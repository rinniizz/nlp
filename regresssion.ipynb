{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡∏´‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠ 24 ‡∏™‡∏¥‡∏á‡∏´‡∏≤ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ 26 ‡∏ò‡∏±‡∏ô‡∏ß‡∏≤ ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏≠...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡∏ï‡∏¥‡∏î‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î=‡∏õ‡∏≠‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏Å‡πá...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡∏û‡∏≠‡∏î‡∏µ‡∏ß‡πà‡∏™‡∏ï‡∏≤‡∏ï‡∏¥‡∏î‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏Å‡∏ï‡∏±‡∏ß‡πÑ‡∏î‡πâ14 ‡∏ß‡∏±‡∏ô‡πÄ‡πÄ‡∏•‡πâ‡∏ß ‡πÄ‡πÄ‡∏ï‡πà‡∏¢‡∏±‡∏á...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏û‡∏§‡∏ï‡∏¥...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6376</th>\n",
       "      <td>‡πÉ‡∏Ñ‡∏£‡πÄ‡∏à‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏≠‡∏≤‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏£‡∏±...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏ó‡∏≤‡∏á‡∏™‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏ô‡πÄ‡∏•‡∏¢‡πÉ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6378</th>\n",
       "      <td>‡∏¢‡∏∑‡πà‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠ 7‡∏ß‡∏±‡∏ô ‡∏ö‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥ ‡∏ó‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>‡∏Ñ‡∏∑‡∏≠ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÇ‡∏ó‡∏£‡∏°‡∏≤‡∏Ç‡∏≤‡∏¢ ‡∏ö‡∏ß‡∏Å‡∏Å‡∏±‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏ß‡∏¥...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6380 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texts category\n",
       "0     ‡∏´‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠ 24 ‡∏™‡∏¥‡∏á‡∏´‡∏≤ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ 26 ‡∏ò‡∏±‡∏ô‡∏ß‡∏≤ ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏≠...      neu\n",
       "1     ‡∏ï‡∏¥‡∏î‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î=‡∏õ‡∏≠‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏Å‡πá...      neu\n",
       "2                                     ‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢      neg\n",
       "3                                     ‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢      neg\n",
       "4     ‡∏û‡∏≠‡∏î‡∏µ‡∏ß‡πà‡∏™‡∏ï‡∏≤‡∏ï‡∏¥‡∏î‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏Å‡∏ï‡∏±‡∏ß‡πÑ‡∏î‡πâ14 ‡∏ß‡∏±‡∏ô‡πÄ‡πÄ‡∏•‡πâ‡∏ß ‡πÄ‡πÄ‡∏ï‡πà‡∏¢‡∏±‡∏á...      neg\n",
       "...                                                 ...      ...\n",
       "6375  ‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏û‡∏§‡∏ï‡∏¥...      neu\n",
       "6376  ‡πÉ‡∏Ñ‡∏£‡πÄ‡∏à‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏≠‡∏≤‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏£‡∏±...      neg\n",
       "6377  ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏ó‡∏≤‡∏á‡∏™‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏ô‡πÄ‡∏•‡∏¢‡πÉ...      neg\n",
       "6378  ‡∏¢‡∏∑‡πà‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠ 7‡∏ß‡∏±‡∏ô ‡∏ö‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥ ‡∏ó‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ...      neu\n",
       "6379  ‡∏Ñ‡∏∑‡∏≠ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÇ‡∏ó‡∏£‡∏°‡∏≤‡∏Ç‡∏≤‡∏¢ ‡∏ö‡∏ß‡∏Å‡∏Å‡∏±‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏ß‡∏¥...      neg\n",
       "\n",
       "[6380 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('convert.csv', names=['texts', 'category'], header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>‚òπÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>üòî</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>üòû</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>üò•</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>‡∏£‡∏≥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26157</th>\n",
       "      <td>pos</td>\n",
       "      <td>‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏ó‡πá‡∏≠‡∏õ‡∏ó‡∏µ‡πà‡∏≠‡∏µ‡∏ã‡∏π‡∏ã‡∏∏‡∏ú‡∏•‡∏¥‡∏ï ‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡πâ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26158</th>\n",
       "      <td>pos</td>\n",
       "      <td>‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏ó‡∏µ‡πà the mall ‡∏ö‡∏≤‡∏á‡πÅ‡∏Ñ ‡∏Ñ‡πà‡∏∞ ‚ù§Ô∏è ‡πÄ‡∏õ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26159</th>\n",
       "      <td>pos</td>\n",
       "      <td>üåû‡πÅ‡∏™‡∏á‡πÅ‡∏î‡∏î‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÑ‡∏ó‡∏¢ ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≠‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏°‡∏©‡∏≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26160</th>\n",
       "      <td>pos</td>\n",
       "      <td>‡πÄ‡∏£‡∏≤‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ ‡∏°‡∏≤‡∏ô‡∏≤‡∏ô‡∏ñ‡∏∂‡∏á 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26161</th>\n",
       "      <td>pos</td>\n",
       "      <td>‡πÄ‡∏≠‡∏≤ mini review ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏ï‡πà‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26162 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                              texts\n",
       "0          neg                                                 ‚òπÔ∏è\n",
       "1          neg                                                  üòî\n",
       "2          neg                                                  üòû\n",
       "3          neg                                                  üò•\n",
       "4          neg                                                 ‡∏£‡∏≥\n",
       "...        ...                                                ...\n",
       "26157      pos  ‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡∏ï‡∏±‡∏ß‡∏ó‡πá‡∏≠‡∏õ‡∏ó‡∏µ‡πà‡∏≠‡∏µ‡∏ã‡∏π‡∏ã‡∏∏‡∏ú‡∏•‡∏¥‡∏ï ‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡πâ...\n",
       "26158      pos  ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏ó‡∏µ‡πà the mall ‡∏ö‡∏≤‡∏á‡πÅ‡∏Ñ ‡∏Ñ‡πà‡∏∞ ‚ù§Ô∏è ‡πÄ‡∏õ...\n",
       "26159      pos  üåû‡πÅ‡∏™‡∏á‡πÅ‡∏î‡∏î‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡πÑ‡∏ó‡∏¢ ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≠‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏°‡∏©‡∏≤...\n",
       "26160      pos  ‡πÄ‡∏£‡∏≤‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ ‡∏°‡∏≤‡∏ô‡∏≤‡∏ô‡∏ñ‡∏∂‡∏á 3...\n",
       "26161      pos  ‡πÄ‡∏≠‡∏≤ mini review ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏ï‡πà‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô l...\n",
       "\n",
       "[26162 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import csv\n",
    "\n",
    "# file1_path = './testtext.txt'\n",
    "# file2_path = './testtext_label.txt'\n",
    "# output_file_path = '_train.csv'\n",
    "\n",
    "# dat = {'text': [], 'sentiment': []}\n",
    "\n",
    "# # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå1\n",
    "# with open(file1_path, 'r', encoding='utf-8') as file1:\n",
    "#     data1 = file1.readlines()\n",
    "#     dat['text'] = [line.strip() for line in data1]\n",
    "\n",
    "# # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå2\n",
    "# with open(file2_path, 'r', encoding='utf-8') as file2:\n",
    "#     data2 = file2.readlines()\n",
    "#     dat['sentiment'] = [line.strip() for line in data2]\n",
    "\n",
    "# with open(output_file_path, 'w', newline='', encoding='utf-8-sig') as csv_file:\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "\n",
    "#     # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n",
    "#     # csv_writer.writerow([\"sentiment\", \"text\"])\n",
    "\n",
    "#     # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV\n",
    "#     for sentiment, text in zip(dat['sentiment'], dat['text']):\n",
    "#         sentiment = sentiment.strip()\n",
    "#         text = text.strip()\n",
    "\n",
    "#         # ‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤ \"q\" ‡πÉ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
    "#         if sentiment == \"q\" or text == \"q\":\n",
    "#             continue\n",
    "\n",
    "#         # ‡∏Ç‡πâ‡∏≤‡∏° index ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ \"q\" ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå \"train_label.txt\"\n",
    "#         if sentiment == \"train\" and text == \"q\":\n",
    "#             continue\n",
    "\n",
    "#         csv_writer.writerow([sentiment, text])\n",
    "\n",
    "# df = pd.read_csv(output_file_path, names=['category', 'texts'], header=None, encoding='utf-8-sig')\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='category'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‡πÄ‡∏â‡∏¢‡πÜ',\n",
       " '‡∏û‡∏ö‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏´‡∏ô',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡πÑ‡∏£',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏¥‡πâ‡∏ô',\n",
       " '‡∏•‡πâ‡∏ß‡∏ô‡πÅ‡∏ï‡πà',\n",
       " '‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤',\n",
       " '‡∏à‡∏∂‡∏á‡πÄ‡∏õ‡πá‡∏ô',\n",
       " '‡πÉ‡∏ä‡πà',\n",
       " '‡πÉ‡∏Ñ‡∏£‡πà‡∏à‡∏∞',\n",
       " '‡πÅ‡∏¢‡∏∞‡πÜ',\n",
       " '‡πÄ‡∏â‡∏¢',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ',\n",
       " '‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤‡∏á',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏õ',\n",
       " '‡πÉ‡∏´‡πâ‡πÅ‡∏î‡πà',\n",
       " '‡∏à‡∏≤‡∏Å',\n",
       " '‡∏Å‡πá‡∏ï‡∏≤‡∏°‡∏ó‡∏µ',\n",
       " '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ô',\n",
       " '‡πÉ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏®‡∏Å',\n",
       " '‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÜ',\n",
       " '‡∏û‡∏≠‡∏™‡∏°',\n",
       " '‡πÅ‡∏ï‡πà‡πÑ‡∏£',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏ô‡∏µ‡πâ',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà',\n",
       " '‡∏Å‡∏£‡∏∞‡∏ú‡∏°',\n",
       " '‡∏à‡∏∂‡∏á‡∏à‡∏∞',\n",
       " '‡∏û‡∏≠‡πÜ',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏î‡∏±‡∏á‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ô‡∏µ‡πâ',\n",
       " '‡πÅ‡∏™‡∏î‡∏á',\n",
       " '‡πÄ‡∏´‡∏•‡πà‡∏≤',\n",
       " '‡∏ñ‡∏∂‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£',\n",
       " '‡∏≠‡∏±‡∏ô‡πÑ‡∏´‡∏ô',\n",
       " '‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà',\n",
       " '‡∏£‡πà‡∏ß‡∏°‡∏°‡∏∑‡∏≠',\n",
       " '‡∏Ñ‡πà‡∏≠‡∏ô‡∏°‡∏≤‡∏ó‡∏≤‡∏á',\n",
       " '‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠',\n",
       " '‡∏ñ‡∏∂‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏£',\n",
       " '‡∏¢‡∏¥‡πà‡∏á‡∏à‡∏ô',\n",
       " '‡∏û‡∏ß‡∏Å‡πÇ‡∏ô‡πâ‡∏ô',\n",
       " '‡πÅ‡∏´‡πà‡∏á‡πÑ‡∏´‡∏ô',\n",
       " '‡∏ã‡∏∞‡∏à‡∏ô',\n",
       " '‡∏ã‡∏∞',\n",
       " '‡∏™‡∏°‡∏±‡∏¢‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏™‡∏¥‡πâ‡∏ô',\n",
       " '‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢',\n",
       " '‡πÄ‡∏¢‡∏≠‡∏∞‡πÜ',\n",
       " '‡∏ô‡∏µ‡πà‡πÄ‡∏≠‡∏á',\n",
       " '‡∏à‡∏±‡∏á',\n",
       " '‡∏î‡∏±‡πà‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡πà‡∏≤',\n",
       " '‡∏¢‡∏∑‡∏ô‡∏¢‡∏á',\n",
       " '‡∏ó‡∏±‡∏ô‡πÉ‡∏î‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏â‡∏∞‡∏ô‡∏µ‡πâ',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡∏´‡∏ô‡∏∂‡πà‡∏á',\n",
       " '‡∏Ñ‡∏£‡∏≤‡πÉ‡∏î',\n",
       " '‡∏™‡πà‡∏ß‡∏ô‡∏î‡∏µ',\n",
       " '‡∏Å‡∏±‡∏ô',\n",
       " '‡∏ó‡∏µ‡πà',\n",
       " '‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß',\n",
       " '‡πÄ‡∏¢‡∏≠‡∏∞',\n",
       " '‡∏ñ‡∏π‡∏Å',\n",
       " '‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£',\n",
       " '‡∏≠‡∏ô‡∏∂‡πà‡∏á',\n",
       " '‡πÉ‡∏´‡∏°‡πà‡πÜ',\n",
       " '‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ú‡∏¢',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏™‡∏π‡∏á‡∏™‡πà‡∏á',\n",
       " '‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠',\n",
       " '‡∏Å‡πá‡πÅ‡∏Ñ‡πà',\n",
       " '‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠',\n",
       " '‡∏ô‡∏µ‡πâ',\n",
       " '‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏≤‡∏ß',\n",
       " '‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà',\n",
       " '‡∏Ç‡∏ì‡∏∞‡πÉ‡∏î‡πÜ',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡∏†‡∏≤‡∏¢‡∏†‡∏≤‡∏Ñ‡∏´‡∏ô‡πâ‡∏≤',\n",
       " '‡∏Ø‡∏•‡∏Ø',\n",
       " '‡∏≠‡∏∑‡πà‡∏ô‡πÜ',\n",
       " '‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö',\n",
       " '‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πâ‡∏á',\n",
       " '‡∏à‡∏ô‡πÅ‡∏°‡πâ‡∏ô',\n",
       " '‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡∏ó‡πç‡∏≤‡πÉ‡∏´‡πâ',\n",
       " '‡∏ï‡πà‡∏≤‡∏á‡πÜ',\n",
       " '‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô',\n",
       " '‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏≤‡∏ß',\n",
       " '‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏≤',\n",
       " '‡πÅ‡∏Å',\n",
       " '‡∏™‡∏π‡∏á',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏ô‡πâ‡∏ô',\n",
       " '‡πÉ‡∏î‡πÜ',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏ó‡∏µ‡πà',\n",
       " '‡∏û‡∏≠‡∏Å‡∏±‡∏ô',\n",
       " '‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏†‡∏≤‡∏¢‡∏´‡∏ô‡πâ‡∏≤',\n",
       " '‡∏ô‡∏±‡∏ö‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà',\n",
       " '‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà',\n",
       " '‡∏¢‡∏¥‡πà‡∏á',\n",
       " '‡∏û‡∏ö',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡πà‡∏≤',\n",
       " '‡∏Å‡πá‡∏ï‡πà‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏¢‡∏¥‡πà‡∏á',\n",
       " '‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà',\n",
       " '‡∏û‡∏≠',\n",
       " '‡πÅ‡∏Å‡πà',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏ô‡∏±‡πà‡∏ô',\n",
       " '‡∏°‡∏±‡πâ‡∏¢‡πÄ‡∏ô‡∏µ‡πà‡∏¢',\n",
       " '‡∏ó‡∏∏‡∏Å‡πÅ‡∏´‡πà‡∏á',\n",
       " '‡∏ö‡∏≠‡∏Å',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ',\n",
       " '‡πÄ‡∏£‡∏¥‡πà‡∏°',\n",
       " '‡∏ï‡∏≤‡∏°',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô',\n",
       " '‡∏ß‡∏±‡∏ô',\n",
       " '‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏¥‡πà‡∏á',\n",
       " '‡∏≠‡∏∞‡πÑ‡∏£',\n",
       " '‡∏¢‡∏±‡∏á‡πÑ‡∏á',\n",
       " '‡∏à‡∏ô‡∏Å‡∏£‡∏∞‡∏ó‡∏±‡πà‡∏á',\n",
       " '‡∏ô‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏ô‡∏µ‡πâ',\n",
       " '‡∏û‡∏ß‡∏Å‡∏°‡∏∂‡∏á',\n",
       " '‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà',\n",
       " '‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ',\n",
       " '‡∏™‡πà‡∏ß‡∏ô‡∏î‡πâ‡∏≠‡∏¢',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô',\n",
       " '‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡∏±‡∏ô',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏î',\n",
       " '‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏´‡∏ô',\n",
       " '‡πÄ‡∏ï‡πá‡∏°‡πÑ‡∏õ‡∏´‡∏°‡∏î',\n",
       " '‡∏°‡∏±‡πä‡∏¢',\n",
       " '‡∏™‡∏ö‡∏≤‡∏¢',\n",
       " '‡∏Å‡∏±‡∏ô‡∏ô‡∏∞',\n",
       " '‡∏´‡∏ô',\n",
       " '‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡∏ï‡∏≤‡∏°‡πÅ‡∏ï‡πà',\n",
       " '‡∏™‡∏±‡πâ‡∏ô',\n",
       " '‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏û‡∏ß‡∏Å‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏¢‡∏∑‡∏ô‡∏ô‡∏≤‡∏ô',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏Ñ‡∏¢',\n",
       " '‡∏ä‡πâ‡∏≤‡∏ô‡∏≤‡∏ô',\n",
       " '‡∏°‡∏±‡πâ‡∏¢‡∏ô‡∏±‡πà‡∏ô',\n",
       " '‡∏Å‡∏≥‡∏´‡∏ô‡∏î',\n",
       " '‡∏≠‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà',\n",
       " '‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡∏à‡∏∞',\n",
       " '‡∏¢‡∏±‡∏á‡πÅ‡∏ï‡πà',\n",
       " '‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠',\n",
       " '‡∏£‡∏∂‡∏ß‡πà‡∏≤',\n",
       " '‡∏ô‡∏±‡∏ö‡πÅ‡∏ï‡πà',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá',\n",
       " '‡∏û‡∏≠‡∏ó‡∏µ',\n",
       " '‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢',\n",
       " '‡∏≠‡∏±‡∏ô‡∏•‡∏∞',\n",
       " '‡∏†‡∏≤‡∏Ñ',\n",
       " '‡∏ã‡∏∂‡πà‡∏á‡πÜ',\n",
       " '‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô',\n",
       " '‡∏¢‡∏¥‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß',\n",
       " '‡πÅ‡∏Ñ‡πà‡∏ô‡∏µ‡πâ',\n",
       " '‡πÅ‡∏ï‡πà‡∏ó‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡∏°‡∏≤',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß',\n",
       " '‡πÄ‡∏´‡∏•‡∏∑‡∏≠',\n",
       " '‡∏¢‡∏∑‡∏ô‡∏¢‡∏≤‡∏ß',\n",
       " '‡∏à‡∏£‡∏¥‡∏á‡πÜ‡∏à‡∏±‡∏á‡πÜ',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á',\n",
       " '‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß',\n",
       " '‡∏ó‡∏∏‡∏Å',\n",
       " '‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß',\n",
       " '‡∏Ñ‡∏á',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£',\n",
       " '‡∏ó‡∏µ',\n",
       " '‡πÑ‡∏î‡πâ‡πÅ‡∏ï‡πà',\n",
       " '‡∏™‡πà‡∏ß‡∏ô',\n",
       " '‡πÑ‡∏Å‡∏•‡πÜ',\n",
       " '‡∏Å‡∏•‡∏∏‡πà‡∏°',\n",
       " '‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á',\n",
       " '‡πÄ‡∏£‡∏≤‡πÜ',\n",
       " '‡∏ô‡∏≥‡∏°‡∏≤',\n",
       " '‡∏¢‡∏≠‡∏°',\n",
       " '‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤',\n",
       " '‡πÇ‡∏ï‡πÜ',\n",
       " '‡∏ó‡∏µ‡πÄ‡∏ñ‡∏≠‡∏∞',\n",
       " '‡∏Å‡∏£‡∏∞‡∏ó‡∏±‡πà‡∏á',\n",
       " '‡∏´‡∏•‡∏±‡∏á',\n",
       " '‡∏£‡πà‡∏ß‡∏°‡∏î‡πâ‡∏ß‡∏¢',\n",
       " '‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏á',\n",
       " '‡πÉ‡∏´‡∏ç‡πà',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô',\n",
       " '‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î',\n",
       " '‡∏î‡∏±‡∏á‡∏Å‡∏•‡πà‡∏≤‡∏ß',\n",
       " '‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°',\n",
       " '‡∏à‡∏ß‡∏ô‡∏à‡∏∞',\n",
       " '‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏µ‡πà',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏ô‡∏µ‡πà‡∏Å‡∏£‡∏∞‡πÑ‡∏£',\n",
       " '‡∏ô‡∏±‡∏ö',\n",
       " '‡∏ã‡∏∂‡πà‡∏á‡∏Å‡∏±‡∏ô',\n",
       " '‡∏Å‡∏•‡∏±‡∏ö',\n",
       " '‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£',\n",
       " '‡πÉ‡∏´‡∏°‡πà',\n",
       " '‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡πÄ‡∏û‡∏£‡∏≤‡∏∞',\n",
       " '‡∏ó‡∏µ‡∏•‡∏∞',\n",
       " '‡∏ô‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏ñ‡∏∂‡∏á‡πÅ‡∏°‡πâ‡∏à‡∏∞',\n",
       " '‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á',\n",
       " '‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡πÜ',\n",
       " '‡∏û‡∏ß‡∏Å',\n",
       " '‡∏ó‡∏∏‡∏Å‡πÜ',\n",
       " '‡πÅ‡∏ï‡πà‡πÄ‡∏°‡∏∑‡πà‡∏≠',\n",
       " '‡∏ä‡πà‡∏ß‡∏¢',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÄ‡∏™‡∏µ‡∏¢',\n",
       " '‡∏ö‡∏≤‡∏á',\n",
       " '‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô',\n",
       " '‡∏ß‡∏±‡∏ô‡πÑ‡∏´‡∏ô',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏î‡∏±‡∏á‡∏ó‡∏µ‡πà',\n",
       " '‡∏ö‡∏±‡∏î‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏ú‡πà‡∏≤‡∏ô',\n",
       " '‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏ï‡πà',\n",
       " '‡∏Å‡πá‡πÑ‡∏î‡πâ',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤',\n",
       " '‡∏ñ‡∏∂‡∏á‡∏ö‡∏±‡∏î‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÉ‡∏´‡πâ‡∏î‡∏µ',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ',\n",
       " '‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô',\n",
       " '‡πÉ‡∏ô',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô',\n",
       " '‡∏Ç‡∏ì‡∏∞‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏â‡∏∞‡∏ô‡∏µ‡πâ',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡∏ó‡∏µ‡πà',\n",
       " '‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡∏ì',\n",
       " '‡πÅ‡∏ï‡πà‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ô‡∏µ‡πâ',\n",
       " '‡∏™‡πà‡∏ß‡∏ô‡∏°‡∏≤‡∏Å',\n",
       " '‡πÅ‡∏ï‡πà‡∏Å‡πá',\n",
       " '‡∏£‡∏∑‡∏≠‡∏ß‡πà‡∏≤',\n",
       " '‡πÅ‡∏ï‡πà‡πÄ‡∏î‡∏¥‡∏°',\n",
       " '‡∏ô‡∏π‡πâ‡∏ô',\n",
       " '‡∏´‡∏≤‡∏Å‡πÅ‡∏°‡πâ‡∏ô',\n",
       " '‡∏à‡πâ‡∏≤',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏¢‡πá‡∏ô',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà',\n",
       " '‡∏ã‡∏∂‡πà‡∏á‡∏Å‡πá',\n",
       " '‡∏≠‡∏±‡∏ô',\n",
       " '‡∏ï‡πâ‡∏≠‡∏á',\n",
       " '‡∏Å‡πá‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà',\n",
       " '‡πÄ‡∏Å‡∏¥‡∏ô‡πÜ',\n",
       " '‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö',\n",
       " '‡∏à‡πâ‡∏∞',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ß‡∏≤‡∏ô',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏à‡∏ô‡∏Å‡∏£‡∏∞‡∏ó‡∏±‡πà‡∏á',\n",
       " '‡πÅ‡∏•‡πâ‡∏ß',\n",
       " '‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ',\n",
       " '‡∏°‡∏±‡πâ‡∏¢‡∏ô‡∏∞',\n",
       " '‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏à‡∏∞',\n",
       " '‡∏Å‡∏≥‡∏•‡∏±‡∏á',\n",
       " '‡∏°‡∏∏‡πà‡∏á',\n",
       " '‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏ß‡πà‡∏≤',\n",
       " '‡∏î‡∏±‡∏á‡∏Å‡∏±‡∏ö',\n",
       " '‡∏¢‡∏¥‡πà‡∏á‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏Å‡∏≤‡∏•',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á',\n",
       " '‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á‡∏™‡∏∏‡∏î',\n",
       " '‡∏Ç‡πâ‡∏≤‡∏û‡πÄ‡∏à‡πâ‡∏≤',\n",
       " '‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô',\n",
       " '‡∏Ñ‡∏≥',\n",
       " '‡∏ï‡πà‡∏≤‡∏á',\n",
       " '‡∏¢‡πà‡∏≠‡∏¢',\n",
       " '‡∏≠‡∏±‡∏ô‡πÉ‡∏î',\n",
       " '‡∏Ñ‡∏£‡∏ö‡∏Ñ‡∏£‡∏±‡∏ô',\n",
       " '‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏ä‡∏¥‡πâ‡∏ô',\n",
       " '‡∏¢‡∏Å‡πÉ‡∏´‡πâ',\n",
       " '‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ',\n",
       " '‡πÉ‡∏Ñ‡∏£‡πà',\n",
       " '‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢',\n",
       " '‡∏°‡∏¥‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô',\n",
       " '‡∏ö‡∏±‡∏î‡∏î‡∏•',\n",
       " '‡πÉ‡∏´‡∏ç‡πà‡πÜ',\n",
       " '‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà',\n",
       " '‡∏ó‡∏≥‡πÑ‡∏£',\n",
       " '‡πÄ‡∏ú‡∏∑‡πà‡∏≠',\n",
       " '‡∏Ñ‡∏£‡∏≤',\n",
       " '‡∏ã‡∏∂‡πà‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏±‡∏ô',\n",
       " '‡∏Ñ‡∏á‡∏≠‡∏¢‡∏π‡πà',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏£‡∏≤‡∏ß',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö',\n",
       " '‡∏î‡∏±‡πà‡∏á‡∏Å‡∏±‡∏ö',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ï‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á',\n",
       " '‡∏¢‡∏≤‡∏Å',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á',\n",
       " '‡∏°‡∏µ',\n",
       " '‡πÄ‡∏ô‡∏µ‡πà‡∏¢‡πÄ‡∏≠‡∏á',\n",
       " '‡∏ó‡∏µ‡πà‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÅ‡∏ï‡πà',\n",
       " '‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤',\n",
       " '‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢',\n",
       " '‡∏ô‡∏≤‡∏¢',\n",
       " '‡∏ß‡∏±‡∏ô‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏ò‡∏≠',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡πÑ‡∏´‡∏ô',\n",
       " '‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö',\n",
       " '‡∏Ç‡∏ß‡∏≤‡∏á',\n",
       " '‡∏ô‡∏≥‡∏û‡∏≤',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏î',\n",
       " '‡∏Å‡πá‡∏à‡∏∞',\n",
       " '‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ',\n",
       " '‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏±‡∏ô‡πÉ‡∏î',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πà‡∏ß‡∏ñ‡∏∂‡∏á',\n",
       " '‡∏Ø',\n",
       " '‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤',\n",
       " '‡∏ö‡∏≤‡∏á‡πÅ‡∏´‡πà‡∏á',\n",
       " '‡∏™‡∏¥‡πà‡∏á‡πÑ‡∏´‡∏ô',\n",
       " '‡∏à‡∏±‡∏î‡∏ï‡∏±‡πâ‡∏á',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ô‡∏µ‡πâ',\n",
       " '‡∏û‡∏∂‡∏á',\n",
       " '‡πÉ‡∏ä‡πâ',\n",
       " '‡∏°‡∏±‡∏Å‡∏à‡∏∞',\n",
       " '‡πÅ‡∏Ñ‡πà‡∏à‡∏∞',\n",
       " '‡∏Ç‡πâ‡∏≤‡∏á‡πÜ',\n",
       " '‡∏û‡∏ß‡∏Å‡∏Å‡∏±‡∏ô',\n",
       " '‡∏ù‡πà‡∏≤‡∏¢‡πÉ‡∏î',\n",
       " '‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏≤‡∏ß',\n",
       " '‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà',\n",
       " '‡∏à‡∏±‡∏î‡∏ó‡∏≥',\n",
       " '‡∏ö‡∏≤‡∏á‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡∏ô‡∏∞',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡πÉ‡∏î',\n",
       " '‡∏ö‡πà‡∏≠‡∏¢',\n",
       " '‡∏Ø‡∏•',\n",
       " '‡πÄ‡∏û‡∏¥‡πà‡∏á',\n",
       " '‡∏ô‡∏¥‡∏î',\n",
       " '‡∏ú‡πà‡∏≤‡∏ô‡πÜ',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà',\n",
       " '‡∏ô‡πç‡∏≤',\n",
       " '‡∏Ç‡πâ‡∏≤‡∏Ø',\n",
       " '‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢',\n",
       " '‡∏™‡∏°‡∏±‡∏¢‡∏ô‡∏µ‡πâ',\n",
       " '‡∏û‡∏≠‡∏Ñ‡∏ß‡∏£',\n",
       " '‡∏Å‡∏ß‡πâ‡∏≤‡∏á',\n",
       " '‡∏ó‡∏≥‡πÑ‡∏°',\n",
       " '‡∏™‡∏π‡πà',\n",
       " '‡∏ó‡∏µ‡πà‡πÜ',\n",
       " '‡∏Å‡∏£‡∏∞‡∏ó‡∏≥',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÜ',\n",
       " '‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏õ‡∏ß‡∏á',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡πÄ‡∏û‡∏µ‡∏¢‡∏á',\n",
       " '‡πÄ‡∏Ñ‡∏¢',\n",
       " '‡∏î‡∏±‡∏á‡∏Å‡∏±‡∏ö‡∏ß‡πà‡∏≤',\n",
       " '‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ',\n",
       " '‡∏à‡∏ô‡πÅ‡∏°‡πâ',\n",
       " '‡∏Å‡πá',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡πÉ‡∏ô‡∏ó‡∏µ‡πà',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£',\n",
       " '‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà',\n",
       " '‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏•‡∏ô‡∏≤‡∏ô',\n",
       " '‡∏à‡∏∂‡∏á',\n",
       " '‡∏ô‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏∞',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πà',\n",
       " '‡∏™‡∏°‡∏±‡∏¢‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡∏Å‡∏±‡∏ö',\n",
       " '‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡πÄ‡∏õ‡πá‡∏ô',\n",
       " '‡πÄ‡∏•‡∏¢',\n",
       " '‡∏û‡∏ß‡∏Å‡∏ô‡∏π‡πâ‡∏ô',\n",
       " '‡∏ó‡∏µ‡πà‡∏ã‡∏∂‡πà‡∏á',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏ß‡∏±‡∏ô',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏à‡∏ô',\n",
       " '‡πÅ‡∏ï‡πà‡∏ß‡πà‡∏≤',\n",
       " '‡∏≠‡∏¢‡∏π‡πà',\n",
       " '‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á',\n",
       " '‡πÄ‡∏ó‡πà‡∏≤‡πÉ‡∏î',\n",
       " '‡∏ñ‡∏∂‡∏á',\n",
       " '‡∏£‡∏ß‡∏°',\n",
       " '‡∏Ç‡∏±‡πâ‡∏ô',\n",
       " '‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏ß‡πà‡∏≤',\n",
       " '‡∏Å‡πà‡∏≠‡∏ô‡πÜ',\n",
       " '‡∏´‡∏ô‡πà‡∏≠‡∏¢',\n",
       " '‡∏ñ‡∏∂‡∏á‡πÅ‡∏°‡πâ',\n",
       " '‡πÄ‡∏ñ‡∏¥‡∏î',\n",
       " '‡πÄ‡∏£‡πá‡∏ß‡πÜ',\n",
       " '‡πÄ‡∏ô‡∏µ‡πà‡∏¢',\n",
       " '‡πÇ‡∏ï',\n",
       " '‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏´‡∏ô‡∏∂‡πà‡∏á',\n",
       " '‡∏£‡∏ß‡∏î',\n",
       " '‡πÄ‡∏â‡∏û‡∏≤‡∏∞',\n",
       " '‡∏ó‡∏±‡∏ô‡∏ó‡∏µ',\n",
       " '‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà',\n",
       " '‡∏à‡∏ô',\n",
       " '‡∏à‡∏∞‡πÑ‡∏î‡πâ',\n",
       " '‡∏£‡∏ß‡∏°‡πÜ',\n",
       " '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ',\n",
       " '‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÑ‡∏£',\n",
       " '‡∏ó‡∏µ‡πà‡∏•‡∏∞',\n",
       " '‡∏Ç‡∏≠‡∏á',\n",
       " '‡∏à‡∏±‡∏î‡πÅ‡∏à‡∏á',\n",
       " '‡πÅ‡∏´‡πà‡∏á‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà',\n",
       " '‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á',\n",
       " '‡∏°‡∏¥‡πÉ‡∏ä‡πà',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏ô‡∏µ‡πà',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ',\n",
       " '‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏±‡∏ô',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏õ‡∏µ',\n",
       " '‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£',\n",
       " '‡∏ñ‡∏π‡∏Å‡πÜ',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢',\n",
       " '‡∏û‡∏ß‡∏Å‡πÄ‡∏ò‡∏≠',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ',\n",
       " '‡∏ô‡∏µ‡πâ‡πÅ‡∏´‡∏•‡πà',\n",
       " '‡∏´‡∏ô‡∏≠',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏£‡∏µ‡∏¢‡∏Å',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÜ',\n",
       " '‡∏Ñ‡πà‡∏≠‡∏ô',\n",
       " '‡πÑ‡∏â‡∏ô',\n",
       " '‡∏û‡∏ß‡∏Å‡∏°‡∏±‡∏ô',\n",
       " '‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î',\n",
       " '‡∏´‡∏≤‡∏Å‡πÅ‡∏°‡πâ‡∏ô‡∏ß‡πà‡∏≤',\n",
       " '‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô',\n",
       " '‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÑ‡∏´‡∏ô',\n",
       " '‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏î',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á',\n",
       " '‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢',\n",
       " '‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á',\n",
       " '‡∏¢‡∏¥‡πà‡∏á‡∏ô‡∏±‡∏Å',\n",
       " '‡∏Å‡πá‡∏î‡∏µ',\n",
       " '‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏°‡∏≤‡∏Å',\n",
       " '‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡∏≠‡∏±‡∏ô‡∏à‡∏∞',\n",
       " '‡∏Å‡∏±‡∏ô‡∏î‡∏µ‡πÑ‡∏´‡∏°',\n",
       " '‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á',\n",
       " '‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏±‡πâ‡∏á',\n",
       " '‡∏Ñ‡∏ß‡∏£',\n",
       " '‡∏ú‡∏π‡πâ',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ó‡∏µ‡πà',\n",
       " '‡∏°‡∏≠‡∏á‡∏ß‡πà‡∏≤',\n",
       " '‡∏£‡∏∑‡∏≠',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡πÜ',\n",
       " '‡∏û‡∏ß‡∏Å‡∏â‡∏±‡∏ô',\n",
       " '‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤',\n",
       " '‡∏à‡∏ß‡∏ö',\n",
       " '‡∏¢‡∏≤‡∏ß',\n",
       " '‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß',\n",
       " '‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏´‡∏ï‡∏∏‡∏ô‡∏µ‡πâ',\n",
       " '‡∏™‡∏π‡∏á‡πÜ',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡πÜ',\n",
       " '‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á',\n",
       " '‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏ô‡∏±‡πà‡∏ô‡πÄ‡∏≠‡∏á',\n",
       " '‡∏á‡πà‡∏≤‡∏¢‡πÜ',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∑‡∏ô',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ß‡πà‡∏≤',\n",
       " '‡∏ô‡πà‡∏≤',\n",
       " '‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠',\n",
       " '‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á',\n",
       " '‡∏Ñ‡∏ß‡∏≤‡∏°',\n",
       " '‡∏Å‡∏±‡∏ô‡πÑ‡∏´‡∏°',\n",
       " '‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡πÉ‡∏î',\n",
       " '‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πâ‡∏≤',\n",
       " '‡πÅ‡∏ï‡πà‡∏•‡∏∞',\n",
       " '‡∏ô‡∏±‡πà‡∏ô',\n",
       " '‡πÄ‡∏Å‡∏¥‡∏î',\n",
       " '‡πÄ‡∏Ñ‡∏¢‡πÜ',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà',\n",
       " '‡∏ö‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß',\n",
       " '‡∏°‡∏±‡∏Å',\n",
       " '‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á',\n",
       " '‡πÄ‡∏£‡∏µ‡∏¢‡∏ö',\n",
       " '‡∏ã‡∏∞‡∏à‡∏ô‡∏Å‡∏£‡∏∞‡∏ó‡∏±‡πà‡∏á',\n",
       " '‡πÇ‡∏î‡∏¢',\n",
       " '‡∏ô‡πà‡∏≤‡∏à‡∏∞',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏ó‡∏≤‡∏á',\n",
       " '‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤',\n",
       " '‡∏ï‡∏ô‡πÄ‡∏≠‡∏á',\n",
       " '‡∏ô‡∏¥‡∏î‡πÜ',\n",
       " '‡πÑ‡∏ß‡πâ',\n",
       " '‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ',\n",
       " '‡∏ö‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏≠‡∏±‡∏ô',\n",
       " '‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏à‡∏∞',\n",
       " '‡∏¢‡∏±‡∏á',\n",
       " '‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà',\n",
       " '‡∏≠‡∏±‡∏ô‡πÜ',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡πÅ‡∏£‡∏Å',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà',\n",
       " '‡∏¢‡∏±‡∏á‡∏à‡∏∞',\n",
       " '‡∏ô‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ',\n",
       " '‡∏≠‡∏∑‡πà‡∏ô',\n",
       " '‡∏à‡∏ô‡∏ó‡∏±‡πà‡∏ß',\n",
       " '‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡πÜ',\n",
       " '‡∏û‡∏ß‡∏Å‡∏ó‡∏µ‡πà',\n",
       " '‡∏ó‡∏µ‡πÜ',\n",
       " '‡∏à‡πä‡∏∞',\n",
       " '‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡∏°‡∏µ‡πÅ‡∏ï‡πà',\n",
       " '‡∏ô‡∏≠‡∏Å‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏°‡∏≤',\n",
       " '‡∏ä‡∏≤‡∏ß',\n",
       " '‡∏ô‡πâ‡∏≠‡∏¢',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡πÇ‡∏ô‡πâ‡∏ô',\n",
       " '‡πÜ',\n",
       " '‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß',\n",
       " '‡∏ú‡∏•',\n",
       " '‡∏ã‡∏∞‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡πÅ‡∏´‡πà‡∏á‡∏ô‡∏µ‡πâ',\n",
       " '‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö',\n",
       " '‡∏Ñ‡∏£‡∏≤‡πÑ‡∏´‡∏ô',\n",
       " '‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ',\n",
       " '‡πÅ‡∏´‡∏•‡∏∞',\n",
       " '‡∏Ç‡∏≠',\n",
       " '‡∏ô‡∏±‡∏Å‡πÜ',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ',\n",
       " '‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏à‡∏∞',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏≤',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏Å‡∏≤‡∏•‡∏ô‡∏≤‡∏ô',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞',\n",
       " '‡∏£‡∏∂',\n",
       " '‡∏ó‡∏£‡∏á',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏µ‡πâ',\n",
       " '‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà',\n",
       " '‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ',\n",
       " '‡∏à‡∏ß‡∏ö‡∏Å‡∏±‡∏ö',\n",
       " '‡∏ó‡∏∏‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡∏´‡∏•‡∏±‡∏á',\n",
       " '‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö',\n",
       " '‡∏ñ‡∏∂‡∏á‡∏ö‡∏±‡∏î‡∏ô‡∏µ‡πâ',\n",
       " '‡∏Å‡∏±‡∏ô‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡∏ö‡∏≤‡∏á‡πÜ',\n",
       " '‡∏Å‡∏≤‡∏£',\n",
       " '‡∏ô‡∏±‡πà‡∏ô‡πÑ‡∏á',\n",
       " '‡∏Ñ‡∏∏‡∏ì‡πÜ',\n",
       " '‡∏à‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ',\n",
       " '‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏´‡∏•‡∏∞',\n",
       " '‡∏ä‡πâ‡∏≤',\n",
       " '‡∏ä‡πâ‡∏≤‡πÜ',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡∏ï‡∏±‡πâ‡∏á',\n",
       " '‡∏°‡∏≠‡∏á',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡πÑ‡∏õ',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏â‡∏∞‡∏ô‡∏µ‡πâ',\n",
       " '‡∏ô‡πâ‡∏≠‡∏¢‡πÜ',\n",
       " '‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡πÜ',\n",
       " '‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì',\n",
       " '‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡∏∞',\n",
       " '‡πÑ‡∏´‡∏ô',\n",
       " '‡πÑ‡∏õ',\n",
       " '‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô',\n",
       " '‡∏ö‡∏±‡∏î‡∏ô‡∏µ‡πâ',\n",
       " '‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö',\n",
       " '‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏î‡πâ‡∏ß‡∏¢',\n",
       " '‡∏°‡∏¥',\n",
       " '‡∏ö‡∏≤‡∏á‡∏Ç‡∏ì‡∏∞',\n",
       " '‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏£',\n",
       " '‡∏≠‡∏≤‡∏à',\n",
       " '‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà',\n",
       " '‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏Ñ‡∏∑‡∏≠',\n",
       " '‡∏à‡∏±‡∏î',\n",
       " '‡∏õ‡∏£‡∏±‡∏ö',\n",
       " '‡∏û‡∏≠‡∏î‡∏µ',\n",
       " '‡∏†‡∏≤‡∏¢‡πÉ‡∏ô',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ó‡∏µ‡πà',\n",
       " '‡πÑ‡∏á',\n",
       " '‡∏ï‡∏ô‡∏Ø',\n",
       " '‡∏ö‡πà‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏´‡∏ï‡∏∏',\n",
       " '‡∏ñ‡∏∂‡∏á‡πÅ‡∏Å‡πà',\n",
       " '‡πÅ‡∏ï‡πà‡πÑ‡∏´‡∏ô',\n",
       " '‡∏û‡∏≠‡πÅ‡∏•‡πâ‡∏ß',\n",
       " '‡πÄ‡∏™‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö',\n",
       " '‡∏ô‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÅ‡∏ï‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏î',\n",
       " '‡∏û‡∏ß‡∏Å‡πÄ‡∏Ç‡∏≤',\n",
       " '‡πÑ‡∏î‡πâ',\n",
       " '‡∏û‡∏≠‡∏ó‡∏µ‡πà',\n",
       " '‡∏ó‡∏µ‡πÉ‡∏î',\n",
       " '‡∏ú‡∏π‡πâ‡πÉ‡∏î',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡∏´‡∏•‡∏±‡∏á',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏û‡∏£‡∏≤‡∏∞',\n",
       " '‡∏Ñ‡∏£‡∏±‡∏ö',\n",
       " '‡∏≠‡∏î‡∏µ‡∏ï',\n",
       " '‡πÑ‡∏î‡πâ‡∏°‡∏≤',\n",
       " '‡∏•‡πâ‡∏ß‡∏ô',\n",
       " '‡πÅ‡∏¢‡∏∞',\n",
       " '‡πÅ‡∏´‡πà‡∏á‡πÉ‡∏î',\n",
       " '‡∏°‡∏≤‡∏Å',\n",
       " '‡πÉ‡∏Ñ‡∏£‡πÜ',\n",
       " '‡πÅ‡∏ï‡πà‡∏ó‡∏µ‡πà',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡∏´‡∏ô‡πâ‡∏≤',\n",
       " '‡πÄ‡∏≠‡πá‡∏á',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡∏ô‡∏π‡πà‡∏ô',\n",
       " '‡πÅ‡∏°‡πâ‡∏Å‡∏£‡∏∞‡∏ó‡∏±‡πà‡∏á',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô',\n",
       " '‡πÄ‡∏ä‡∏∑‡πà‡∏≠',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ',\n",
       " '‡πÅ‡∏Ñ‡πà',\n",
       " '‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏ß‡πà‡∏≤',\n",
       " '‡∏•‡πâ‡∏ß‡∏ô‡∏à‡∏ô',\n",
       " '‡πÄ‡∏´‡πá‡∏ô‡∏à‡∏∞',\n",
       " '‡∏°‡∏∂‡∏á',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞',\n",
       " '‡∏ó‡∏ß‡πà‡∏≤',\n",
       " '‡∏ï‡πà‡∏≤‡∏á‡∏Å‡πá',\n",
       " '‡∏à‡∏≥',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á',\n",
       " '‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠',\n",
       " '‡∏Ñ‡∏¥‡∏î',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏°‡∏≤',\n",
       " '‡πÅ‡∏•‡∏∞',\n",
       " '‡∏û‡∏ß‡∏Å‡∏ô‡∏µ‡πâ',\n",
       " '‡πÄ‡∏≠‡∏á',\n",
       " '‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏û‡∏µ‡∏¢‡∏á',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢',\n",
       " '‡πÄ‡∏´‡πá‡∏ô',\n",
       " '‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏à‡∏∞',\n",
       " '‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô',\n",
       " '‡∏ö‡∏≤‡∏á‡∏ó‡∏µ',\n",
       " '‡∏¢‡∏Å',\n",
       " '‡πÉ‡∏ï‡πâ',\n",
       " '‡∏£‡∏∞‡∏¢‡∏∞‡πÜ',\n",
       " '‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤',\n",
       " '‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡∏ß‡∏£',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏•‡∏≤‡∏¢',\n",
       " '‡πÑ‡∏õ‡πà',\n",
       " '‡∏£‡∏≤‡∏¢',\n",
       " '‡∏´‡∏≤‡∏Å‡πÅ‡∏°‡πâ',\n",
       " '‡∏à‡∏ô‡∏ï‡∏•‡∏≠‡∏î',\n",
       " '‡∏á‡πà‡∏≤‡∏¢',\n",
       " '‡∏ô‡∏µ‡πâ‡πÄ‡∏≠‡∏á',\n",
       " '‡∏ö‡∏ô',\n",
       " '‡πÅ‡∏°‡πâ',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î',\n",
       " '‡πÄ‡∏Ç‡∏≤',\n",
       " '‡∏Ç‡πâ‡∏≤',\n",
       " '‡∏ï‡∏£‡∏á‡πÜ',\n",
       " '‡πÄ‡∏ï‡πá‡∏°‡πÜ',\n",
       " '‡∏û‡∏ß‡∏Å‡πÅ‡∏Å',\n",
       " '‡∏à‡∏∞',\n",
       " '‡∏î‡∏±‡∏á‡πÄ‡∏Å‡πà‡∏≤',\n",
       " '‡∏û‡∏ß‡∏Å‡∏ó‡πà‡∏≤‡∏ô',\n",
       " '‡πÄ‡∏â‡∏Å‡πÄ‡∏ä‡πà‡∏ô',\n",
       " '‡∏¢‡∏±‡∏á‡∏á‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏î‡∏±‡∏á',\n",
       " '‡∏ñ‡∏∂‡∏á‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤',\n",
       " '‡∏ó‡∏µ‡πà‡πÅ‡∏´‡πà‡∏á‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏à‡∏ô‡∏ñ‡∏∂‡∏á',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏ô',\n",
       " '‡∏™‡πà‡∏ß‡∏ô‡∏ô‡πâ‡∏≠‡∏¢',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ó‡∏µ‡πà',\n",
       " '‡∏´‡∏•‡∏≤‡∏¢',\n",
       " '‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏î‡∏±‡∏á‡∏ß‡πà‡∏≤',\n",
       " '‡∏ó‡∏±‡πâ‡∏á',\n",
       " '‡∏à‡∏ô‡∏ö‡∏±‡∏î‡∏ô‡∏µ‡πâ',\n",
       " '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Å‡πâ‡∏≠‡∏ô',\n",
       " '‡∏ô‡∏≠‡∏Å',\n",
       " '‡∏î‡∏±‡∏á',\n",
       " '‡∏´‡∏≤‡∏Å',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢',\n",
       " '‡∏ñ‡πâ‡∏≤',\n",
       " '‡∏Å‡πá‡∏ï‡∏≤‡∏°',\n",
       " '‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏î',\n",
       " '‡∏û‡∏≠‡πÄ‡∏û‡∏µ‡∏¢‡∏á',\n",
       " '‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠',\n",
       " '‡∏†‡∏≤‡∏¢‡∏†‡∏≤‡∏Ñ',\n",
       " '‡∏Ç‡∏ì‡∏∞‡∏´‡∏ô‡∏∂‡πà‡∏á',\n",
       " '‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç',\n",
       " '‡πÄ‡∏¢‡∏≠‡∏∞‡πÅ‡∏¢‡∏∞',\n",
       " '‡∏™‡∏¥‡πà‡∏á',\n",
       " '‡πÉ‡∏´‡πâ‡∏°‡∏≤',\n",
       " '‡∏´‡∏≤‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡πÜ',\n",
       " '‡∏Ñ‡∏á‡∏à‡∏∞',\n",
       " '‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á',\n",
       " '‡∏à‡∏á',\n",
       " '‡∏ï‡∏≤‡∏°‡πÜ',\n",
       " '‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡∏∂‡πà‡∏á',\n",
       " '‡πÄ‡∏î‡∏µ‡∏¢‡∏ß',\n",
       " '‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏ï‡∏±‡∏ß',\n",
       " '‡∏¢‡∏¥‡πà‡∏á‡πÉ‡∏´‡∏ç‡πà',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ï‡πà',\n",
       " '‡πÑ‡∏£',\n",
       " '‡∏Ç‡∏ì‡∏∞‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô',\n",
       " '‡πÄ‡∏•‡πà‡∏≤‡∏ß‡πà‡∏≤',\n",
       " '‡∏û‡∏π‡∏î',\n",
       " '‡∏à‡∏î',\n",
       " '‡∏ï‡∏£‡∏á',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÉ‡∏î',\n",
       " '‡∏ó‡∏≥‡πÉ‡∏´‡πâ',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å',\n",
       " '‡∏Ç‡πâ‡∏≤‡∏á‡∏•‡πà‡∏≤‡∏á',\n",
       " '‡∏û‡∏≠‡∏ï‡∏±‡∏ß',\n",
       " '‡πÄ‡∏´‡∏ï‡∏∏‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏Ç‡∏ì‡∏∞‡πÉ‡∏î',\n",
       " '‡∏Ñ‡∏£‡∏ö',\n",
       " '‡∏ô‡∏±‡πà‡∏ô‡πÄ‡∏≠‡∏á',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πà‡∏ß‡∏ó‡∏±‡πâ‡∏á',\n",
       " '‡∏•‡∏∞',\n",
       " '‡∏´‡∏≤‡πÉ‡∏ä‡πà',\n",
       " '‡πÄ‡∏™‡∏£‡πá‡∏à',\n",
       " '‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤',\n",
       " '‡∏ô‡∏µ‡πà‡∏ô‡∏≤',\n",
       " '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢',\n",
       " '‡∏≠‡∏±‡∏ô‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å',\n",
       " '‡∏ä‡πà‡∏ß‡∏á',\n",
       " '‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô',\n",
       " '‡πÄ‡∏Å‡∏¥‡∏ô',\n",
       " '‡πÉ‡∏Å‡∏•‡πâ',\n",
       " '‡∏ô‡∏±‡πâ‡∏ô‡πÜ',\n",
       " '‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏∞',\n",
       " '‡πÅ‡∏´‡πà‡∏á',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏ó‡∏±‡πà‡∏ß',\n",
       " '‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏Å‡∏¥‡∏ô',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏°‡∏ß‡∏•',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏à‡∏ô',\n",
       " '‡∏à‡∏ß‡∏ö‡∏à‡∏ô',\n",
       " '‡∏°‡∏±‡πâ‡∏¢',\n",
       " '‡∏´‡∏°‡∏î‡∏Å‡∏±‡∏ô',\n",
       " '‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô',\n",
       " '‡πÅ‡∏ö‡∏ö',\n",
       " '‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠',\n",
       " '‡πÅ‡∏Ñ‡πà‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô',\n",
       " '‡∏õ‡∏£‡∏∞‡∏™‡∏ö',\n",
       " '‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ',\n",
       " '‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà',\n",
       " '‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á',\n",
       " '‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏Å‡πà',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ',\n",
       " '‡∏†‡∏≤‡∏Ñ‡∏Ø',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡πÑ‡∏î‡πâ',\n",
       " '‡πÅ‡∏ï‡πà‡∏à‡∏∞',\n",
       " '‡∏Ç‡∏≤‡∏î',\n",
       " '‡∏°‡∏¥‡πÑ‡∏î‡πâ',\n",
       " '‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô',\n",
       " '‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏¢‡∏¥‡πà‡∏á‡∏ô‡∏±‡∏Å',\n",
       " '‡∏°‡∏±‡πâ‡∏¢‡∏•‡πà‡∏∞',\n",
       " '‡πÉ‡∏ä‡πà‡πÑ‡∏´‡∏°',\n",
       " '‡∏´‡∏≤‡∏£‡∏∑‡∏≠',\n",
       " '‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô',\n",
       " '‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏ñ‡∏∂‡∏á‡∏à‡∏∞',\n",
       " '‡πÅ‡∏°‡πâ‡πÅ‡∏ï‡πà',\n",
       " '‡∏ô‡∏≥',\n",
       " '‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å',\n",
       " '‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏£',\n",
       " '‡∏Ñ‡∏∏‡∏ì',\n",
       " '‡∏ã‡∏∂‡πà‡∏á‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠',\n",
       " '‡∏Ç‡∏ì‡∏∞',\n",
       " '‡πÉ‡∏´‡∏ç‡πà‡πÇ‡∏ï',\n",
       " '‡∏ï‡∏•‡∏≠‡∏î‡∏ñ‡∏∂‡∏á',\n",
       " '‡πÄ‡∏´‡∏ï‡∏∏‡πÑ‡∏£',\n",
       " '‡∏ß‡∏±‡∏ô‡πÉ‡∏î',\n",
       " '‡∏°‡∏±‡∏ô',\n",
       " '‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤',\n",
       " '‡∏ô‡∏±‡∏Å',\n",
       " '‡∏Ñ‡πà‡∏≠‡∏¢',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô',\n",
       " '‡∏†‡∏≤‡∏¢',\n",
       " '‡∏´‡∏ô‡∏∂‡πà‡∏á',\n",
       " '‡πÄ‡∏û‡∏£‡∏≤‡∏∞',\n",
       " '‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÄ‡∏û‡∏£‡∏≤‡∏∞',\n",
       " '‡∏ï‡∏ô',\n",
       " '‡∏´‡∏£‡∏∑‡∏≠',\n",
       " '‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏±‡∏á',\n",
       " '‡πÉ‡∏Å‡∏•‡πâ‡πÜ',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á',\n",
       " '‡∏ô‡∏µ‡πà‡πÅ‡∏´‡∏•‡∏∞',\n",
       " '‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏ñ‡∏≠‡∏∞',\n",
       " '‡∏¢‡πà‡∏≠‡∏°',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏ó‡∏µ',\n",
       " '‡∏™‡∏±‡πâ‡∏ô‡πÜ',\n",
       " '‡∏™‡∏∏‡∏î‡πÜ',\n",
       " '‡∏¢‡∏±‡∏á‡∏Ñ‡∏á',\n",
       " '‡∏à‡∏±‡∏ö',\n",
       " '‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡πÑ‡∏õ',\n",
       " '‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏±‡∏ô',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤',\n",
       " '‡∏à‡πã‡∏≤',\n",
       " '‡∏ñ‡πâ‡∏≤‡∏à‡∏∞',\n",
       " '‡∏Å‡∏π',\n",
       " '‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô',\n",
       " '‡∏Ç‡∏ß‡∏≤‡∏á‡πÜ',\n",
       " '‡∏™‡πç‡∏≤‡∏´‡∏£‡∏±‡∏ö',\n",
       " '‡∏Ñ‡∏∞',\n",
       " '‡∏à‡∏±‡∏á‡πÜ',\n",
       " '‡∏à‡∏π‡πà‡πÜ',\n",
       " '‡∏£‡πà‡∏ß‡∏°',\n",
       " '‡∏õ‡∏£‡∏≤‡∏Å‡∏è',\n",
       " '‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á',\n",
       " '‡∏ñ‡∏∂‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠',\n",
       " '‡∏¢‡∏±‡∏á‡πÇ‡∏á‡πâ‡∏ô',\n",
       " '‡∏ó‡∏µ‡πÑ‡∏£',\n",
       " '‡∏ú‡∏¥‡∏î',\n",
       " '‡∏ô‡πà‡∏∞',\n",
       " '‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏≤',\n",
       " '‡∏à‡∏≥‡∏û‡∏ß‡∏Å',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡πâ‡∏ß‡∏¢',\n",
       " '‡∏ö‡∏±‡∏î‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏ô‡∏µ‡πâ',\n",
       " '‡∏Ç‡∏∂‡πâ‡∏ô',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡πÅ‡∏•‡πâ‡∏ß',\n",
       " '‡∏â‡∏±‡∏ô',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏î‡∏±‡∏á‡πÄ‡∏Å‡πà‡∏≤',\n",
       " '‡πÑ‡∏Å‡∏•',\n",
       " '‡∏û‡∏∂‡πà‡∏á',\n",
       " '‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á',\n",
       " '‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö',\n",
       " '‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÉ‡∏î',\n",
       " '‡πÅ‡∏Ñ‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á',\n",
       " '‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô',\n",
       " '‡∏ö‡πà‡∏≠‡∏¢‡πÜ',\n",
       " '‡πÅ‡∏°‡πâ‡∏ô‡∏ß‡πà‡∏≤',\n",
       " '‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á',\n",
       " '‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏ß',\n",
       " '‡∏Ñ‡∏∑‡∏≠',\n",
       " '‡∏î‡πâ‡∏≤‡∏ô',\n",
       " '‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö',\n",
       " '‡∏î‡∏±‡∏á‡πÄ‡∏Ñ‡∏¢',\n",
       " '‡∏ã‡∏∂‡πà‡∏á',\n",
       " '‡∏ä‡πà‡∏ß‡∏á‡∏ó‡πâ‡∏≤‡∏¢',\n",
       " '‡∏ó‡∏≤‡∏á',\n",
       " '‡∏Ç‡πâ‡∏≤‡∏á',\n",
       " '‡∏ó‡∏µ‡πà‡πÉ‡∏î',\n",
       " '‡πÄ‡∏Ç‡πâ‡∏≤',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î',\n",
       " '‡∏û‡∏£‡πâ‡∏≠‡∏°',\n",
       " '‡∏™‡∏∑‡∏ö‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á',\n",
       " '‡∏Å‡∏±‡∏ô‡πÄ‡∏ñ‡∏≠‡∏∞',\n",
       " '‡∏™‡∏°‡∏±‡∏¢‡πÇ‡∏ô‡πâ‡∏ô',\n",
       " '‡∏≠‡∏≠‡∏Å',\n",
       " '‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ',\n",
       " '‡πÅ‡∏ï‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á',\n",
       " '‡∏´‡∏ô‡∏≠‡∏¢',\n",
       " '‡πÄ‡∏Å‡πá‡∏ö',\n",
       " '‡∏ô‡∏±‡πà‡∏ô‡πÄ‡∏õ‡πá‡∏ô',\n",
       " '‡∏à‡∏£‡∏î‡∏Å‡∏±‡∏ö',\n",
       " '‡πÅ‡∏´‡πà‡∏á‡πÇ‡∏ô‡πâ‡∏ô',\n",
       " '\\ufeff‡πÜ',\n",
       " '‡∏Ñ‡πà‡∏∞',\n",
       " '‡∏ô‡∏µ‡πà',\n",
       " '‡πÅ‡∏ï‡πà‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏û‡∏∑‡πà‡∏≠',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡πÜ',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡∏•‡∏∞',\n",
       " '‡∏´‡∏°‡∏î‡∏™‡∏¥‡πâ‡∏ô',\n",
       " '‡πÉ‡∏´‡πâ‡πÑ‡∏õ',\n",
       " '‡∏î‡∏±‡πà‡∏á‡πÄ‡∏Å‡πà‡∏≤',\n",
       " '‡∏ô‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏ó‡∏µ‡πà',\n",
       " '‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à',\n",
       " '‡πÄ‡∏™‡∏µ‡∏¢‡∏à‡∏ô‡∏ñ‡∏∂‡∏á',\n",
       " '‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡πà',\n",
       " '‡πÄ‡∏£‡∏≤',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÑ‡∏´‡∏ô',\n",
       " '‡∏û‡∏≤',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡∏£‡∏∞‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÄ‡∏õ‡∏¥‡∏î',\n",
       " '‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏µ‡πâ',\n",
       " '‡∏≠‡∏≤‡∏à‡∏à‡∏∞',\n",
       " '‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á',\n",
       " '‡πÄ‡∏û‡∏¥‡πà‡∏°',\n",
       " '‡∏à‡∏£‡∏î',\n",
       " '‡πÄ‡∏ä‡πà‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏≠‡∏á',\n",
       " '‡∏û‡∏ß‡∏Å‡∏Ñ‡∏∏‡∏ì',\n",
       " '‡∏î‡∏±‡πà‡∏á',\n",
       " '‡∏¢‡∏¥‡πà‡∏á‡∏à‡∏∞',\n",
       " '‡∏Ñ‡∏£‡∏±‡∏ô',\n",
       " '‡πÅ‡∏£‡∏Å',\n",
       " '‡∏Å‡πá‡∏ï‡∏≤‡∏°‡πÅ‡∏ï‡πà',\n",
       " '‡πÉ‡∏Ñ‡∏£',\n",
       " '‡∏≠‡∏µ‡∏Å',\n",
       " '‡πÑ‡∏°‡πà',\n",
       " '‡πÉ‡∏´‡πâ',\n",
       " '‡∏û‡∏≠‡πÄ‡∏´‡∏°‡∏≤‡∏∞',\n",
       " '‡∏Ñ‡πà‡∏≠‡∏¢‡πÑ‡∏õ‡∏ó‡∏≤‡∏á',\n",
       " '‡∏™‡∏°‡∏±‡∏¢',\n",
       " '‡∏à‡∏£‡∏¥‡∏á‡πÜ',\n",
       " '‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢',\n",
       " '‡∏à‡∏ß‡∏ô',\n",
       " '‡∏ó‡∏±‡πà‡∏ß',\n",
       " '‡∏ô‡∏≤‡∏ô',\n",
       " '‡πÄ‡∏ó‡πà‡∏≤',\n",
       " '‡∏ô‡∏µ‡πà‡πÑ‡∏á',\n",
       " '‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏ô‡πâ‡∏ô',\n",
       " '‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢',\n",
       " '‡∏ô‡∏≤‡∏á',\n",
       " '‡∏£‡∏∞‡∏¢‡∏∞',\n",
       " '‡∏ï‡πà‡∏≠',\n",
       " '‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ',\n",
       " '‡∏ú‡∏¥‡∏î‡πÜ',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ó‡∏µ‡πà',\n",
       " '‡∏Å‡∏•‡πà‡∏≤‡∏ß',\n",
       " '‡∏´‡∏°‡∏î',\n",
       " '‡∏Ç‡∏ì‡∏∞‡∏ó‡∏µ‡πà',\n",
       " '‡∏™‡πà‡∏á',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô',\n",
       " '‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô',\n",
       " '‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤',\n",
       " '‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á',\n",
       " '‡∏ô‡∏≤‡∏ô‡πÜ',\n",
       " '‡∏™‡∏∏‡∏î',\n",
       " '‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏µ‡πâ',\n",
       " '‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô',\n",
       " '‡πÄ‡∏£‡πá‡∏ß',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á',\n",
       " '‡∏Ñ‡∏£‡∏≤‡∏ß‡πÜ',\n",
       " '‡∏°‡∏∏‡πà‡∏á‡∏´‡∏°‡∏≤‡∏¢',\n",
       " '‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏£‡∏±‡∏ö',\n",
       " '‡∏û‡∏≠‡∏à‡∏∞',\n",
       " '‡∏î‡∏±‡πà‡∏á‡πÄ‡∏Ñ‡∏¢',\n",
       " '‡∏≠‡∏¢‡∏≤‡∏Å',\n",
       " '‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£',\n",
       " '‡∏õ‡∏¥‡∏î',\n",
       " '‡∏à‡∏ß‡∏ô‡πÄ‡∏à‡∏µ‡∏¢‡∏ô',\n",
       " '‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô',\n",
       " '‡∏à‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠',\n",
       " '‡πÄ‡∏õ‡πá‡∏ô‡∏î‡∏±‡∏á',\n",
       " '‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤',\n",
       " '‡∏•‡∏á',\n",
       " '‡∏™‡∏¥‡πà‡∏á‡πÉ‡∏î',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô',\n",
       " '‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥',\n",
       " '‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡∏Å',\n",
       " '‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ',\n",
       " '‡∏¢‡∏±‡∏á‡∏á‡∏µ‡πâ',\n",
       " '‡∏ã‡∏∞‡∏à‡∏ô‡∏ñ‡∏∂‡∏á',\n",
       " '‡∏à‡∏£‡∏¥‡∏á',\n",
       " '‡πÄ‡∏•‡πá‡∏Å',\n",
       " '‡πÄ‡∏•‡πá‡∏Å‡πÜ',\n",
       " '‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏ß‡πà‡∏≤',\n",
       " '‡∏™‡∏¥‡πà‡∏á‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏™‡∏£‡πá‡∏à',\n",
       " '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß',\n",
       " '‡∏ù‡πà‡∏≤‡∏¢',\n",
       " '‡∏Å‡∏£‡∏∞‡∏ô‡∏±‡πâ‡∏ô',\n",
       " '‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô',\n",
       " '‡∏£‡∏ß‡∏°‡∏î‡πâ‡∏ß‡∏¢',\n",
       " '‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏£',\n",
       " '‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp.corpus.common import thai_stopwords\n",
    "thai_stopwords = list(thai_stopwords())\n",
    "\n",
    "# len(thai_stopwords)\n",
    "thai_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>category</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡∏´‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠ 24 ‡∏™‡∏¥‡∏á‡∏´‡∏≤ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ 26 ‡∏ò‡∏±‡∏ô‡∏ß‡∏≤ ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏≠...</td>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏´‡∏≤‡∏¢ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡πÄ‡∏°‡∏∑‡πà‡∏≠ 24 ‡∏™‡∏¥‡∏á‡∏´‡∏≤ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ 26 ‡∏ò‡∏±‡∏ô‡∏ß‡∏≤ ‡∏à‡∏∞ ‡πÄ‡∏õ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡∏ï‡∏¥‡∏î‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î=‡∏õ‡∏≠‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏Å‡πá...</td>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏ï‡∏¥‡∏î ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î = ‡∏õ‡∏≠‡∏î ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡πÑ‡∏°‡πà ‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏£...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢</td>\n",
       "      <td>neg</td>\n",
       "      <td>‡πÄ‡∏ä‡∏∑‡πâ‡∏≠ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢</td>\n",
       "      <td>neg</td>\n",
       "      <td>‡πÄ‡∏ä‡∏∑‡πâ‡∏≠ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡∏û‡∏≠‡∏î‡∏µ‡∏ß‡πà‡∏™‡∏ï‡∏≤‡∏ï‡∏¥‡∏î‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏Å‡∏ï‡∏±‡∏ß‡πÑ‡∏î‡πâ14 ‡∏ß‡∏±‡∏ô‡πÄ‡πÄ‡∏•‡πâ‡∏ß ‡πÄ‡πÄ‡∏ï‡πà‡∏¢‡∏±‡∏á...</td>\n",
       "      <td>neg</td>\n",
       "      <td>‡∏û‡∏≠‡∏î‡∏µ ‡∏ß‡πà‡∏™ ‡∏ï‡∏≤ ‡∏ï‡∏¥‡∏î ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏Å‡∏ï‡∏±‡∏ß ‡πÑ‡∏î‡πâ 14 ‡∏ß‡∏±‡∏ô ‡πÄ‡πÄ‡∏•‡πâ‡∏ß ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏û‡∏§‡∏ï‡∏¥...</td>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏ô‡∏µ‡πâ ‡∏Ñ‡∏ß‡∏£ ‡πÉ‡∏ä‡πâ ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™ ‡∏ô‡∏µ‡πâ ‡πÉ‡∏ô ‡∏Å‡∏≤‡∏£ ‡πÄ‡∏õ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6376</th>\n",
       "      <td>‡πÉ‡∏Ñ‡∏£‡πÄ‡∏à‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏≠‡∏≤‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏£‡∏±...</td>\n",
       "      <td>neg</td>\n",
       "      <td>‡πÉ‡∏Ñ‡∏£ ‡πÄ‡∏à‡∏≠ ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏≠‡∏≤‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö ‡∏Ç‡∏≠‡∏á ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏ó‡∏≤‡∏á‡∏™‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏ô‡πÄ‡∏•‡∏¢‡πÉ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>‡πÑ‡∏°‡πà ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ ‡∏ö‡∏¥‡∏ô ‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏ó‡∏≤‡∏á ‡∏™‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ö...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6378</th>\n",
       "      <td>‡∏¢‡∏∑‡πà‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠ 7‡∏ß‡∏±‡∏ô ‡∏ö‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥ ‡∏ó‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>‡∏¢‡∏∑‡πà‡∏ô ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠ 7 ‡∏ß‡∏±‡∏ô ‡∏ö‡∏≠‡∏Å ‡πÑ‡∏°‡πà ‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥ ‡∏ó‡∏±‡πâ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>‡∏Ñ‡∏∑‡∏≠ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÇ‡∏ó‡∏£‡∏°‡∏≤‡∏Ç‡∏≤‡∏¢ ‡∏ö‡∏ß‡∏Å‡∏Å‡∏±‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏ß‡∏¥...</td>\n",
       "      <td>neg</td>\n",
       "      <td>‡∏Ñ‡∏∑‡∏≠ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏±‡πâ‡∏ô ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô ‡πÇ‡∏ó‡∏£ ‡∏°‡∏≤ ‡∏Ç‡∏≤‡∏¢ ‡∏ö‡∏ß‡∏Å ‡∏Å‡∏±‡∏ö ‡∏ä‡πà‡∏ß‡∏á ‡∏ó‡∏µ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6380 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texts category  \\\n",
       "0     ‡∏´‡∏≤‡∏¢‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠ 24 ‡∏™‡∏¥‡∏á‡∏´‡∏≤ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ 26 ‡∏ò‡∏±‡∏ô‡∏ß‡∏≤ ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏≠...      neu   \n",
       "1     ‡∏ï‡∏¥‡∏î‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î=‡∏õ‡∏≠‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏Å‡πá...      neu   \n",
       "2                                     ‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢      neg   \n",
       "3                                     ‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢      neg   \n",
       "4     ‡∏û‡∏≠‡∏î‡∏µ‡∏ß‡πà‡∏™‡∏ï‡∏≤‡∏ï‡∏¥‡∏î‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏Å‡∏ï‡∏±‡∏ß‡πÑ‡∏î‡πâ14 ‡∏ß‡∏±‡∏ô‡πÄ‡πÄ‡∏•‡πâ‡∏ß ‡πÄ‡πÄ‡∏ï‡πà‡∏¢‡∏±‡∏á...      neg   \n",
       "...                                                 ...      ...   \n",
       "6375  ‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏û‡∏§‡∏ï‡∏¥...      neu   \n",
       "6376  ‡πÉ‡∏Ñ‡∏£‡πÄ‡∏à‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏≠‡∏≤‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏£‡∏±...      neg   \n",
       "6377  ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏ó‡∏≤‡∏á‡∏™‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏ô‡πÄ‡∏•‡∏¢‡πÉ...      neg   \n",
       "6378  ‡∏¢‡∏∑‡πà‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠ 7‡∏ß‡∏±‡∏ô ‡∏ö‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥ ‡∏ó‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ...      neu   \n",
       "6379  ‡∏Ñ‡∏∑‡∏≠ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÇ‡∏ó‡∏£‡∏°‡∏≤‡∏Ç‡∏≤‡∏¢ ‡∏ö‡∏ß‡∏Å‡∏Å‡∏±‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏ß‡∏¥...      neg   \n",
       "\n",
       "                                            text_tokens  \n",
       "0     ‡∏´‡∏≤‡∏¢ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡πÄ‡∏°‡∏∑‡πà‡∏≠ 24 ‡∏™‡∏¥‡∏á‡∏´‡∏≤ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ 26 ‡∏ò‡∏±‡∏ô‡∏ß‡∏≤ ‡∏à‡∏∞ ‡πÄ‡∏õ...  \n",
       "1     ‡∏ï‡∏¥‡∏î ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î = ‡∏õ‡∏≠‡∏î ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡πÑ‡∏°‡πà ‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏£...  \n",
       "2                                   ‡πÄ‡∏ä‡∏∑‡πâ‡∏≠ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢  \n",
       "3                                   ‡πÄ‡∏ä‡∏∑‡πâ‡∏≠ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏û‡∏¥‡∏©‡∏£‡πâ‡∏≤‡∏¢  \n",
       "4     ‡∏û‡∏≠‡∏î‡∏µ ‡∏ß‡πà‡∏™ ‡∏ï‡∏≤ ‡∏ï‡∏¥‡∏î ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏Å‡∏ï‡∏±‡∏ß ‡πÑ‡∏î‡πâ 14 ‡∏ß‡∏±‡∏ô ‡πÄ‡πÄ‡∏•‡πâ‡∏ß ...  \n",
       "...                                                 ...  \n",
       "6375  ‡∏ó‡∏µ‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏ô‡∏µ‡πâ ‡∏Ñ‡∏ß‡∏£ ‡πÉ‡∏ä‡πâ ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™ ‡∏ô‡∏µ‡πâ ‡πÉ‡∏ô ‡∏Å‡∏≤‡∏£ ‡πÄ‡∏õ...  \n",
       "6376  ‡πÉ‡∏Ñ‡∏£ ‡πÄ‡∏à‡∏≠ ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÄ‡∏≠‡∏≤‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö ‡∏Ç‡∏≠‡∏á ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô...  \n",
       "6377  ‡πÑ‡∏°‡πà ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ ‡∏ö‡∏¥‡∏ô ‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏ó‡∏≤‡∏á ‡∏™‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ö...  \n",
       "6378  ‡∏¢‡∏∑‡πà‡∏ô ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠ 7 ‡∏ß‡∏±‡∏ô ‡∏ö‡∏≠‡∏Å ‡πÑ‡∏°‡πà ‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥ ‡∏ó‡∏±‡πâ...  \n",
       "6379  ‡∏Ñ‡∏∑‡∏≠ ‡∏ï‡∏≠‡∏ô‡∏ô‡∏±‡πâ‡∏ô ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô ‡πÇ‡∏ó‡∏£ ‡∏°‡∏≤ ‡∏Ç‡∏≤‡∏¢ ‡∏ö‡∏ß‡∏Å ‡∏Å‡∏±‡∏ö ‡∏ä‡πà‡∏ß‡∏á ‡∏ó‡∏µ...  \n",
       "\n",
       "[6380 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pythainlp import word_tokenize\n",
    "def text_process(text):\n",
    "    # final = \"\".join(u for u in text if u not in (\"?\", \".\", \";\", \":\", \"!\", '\"', \"‡πÜ\", \"‡∏Ø\",\"‚Ñ¢\",\"#\",\"/\",\"ÔøΩ\",\"üòÖ\",\"üí®\",\"üò¨\",\"üëçüèª\",\"‚ÄºÔ∏è\",\"@\",\"/\",\"<\",\">\",\"üòÇ\",\"üò≠\",\"‚ò∫Ô∏è\",\"‚ù§Ô∏è\",\"üòç\",\"%\",\")\",\"(\",\"*\",\"\\\"\",\"'\",\",\",\".\",\"‚Äù\",\"&\",\"^\",\"!\",\"~\",\"-\",\"+\",\"{\",\"}\",\"[\",\"]\",\"?\"\n",
    "    #                                              ,\"A\",\"a\",\"B\",\"b\",\"C\",\"c\",\"D\",\"d\",\"E\",\"e\",\"F\",\"f\"\n",
    "    #                                              ,\"G\",\"g\",\"H\",\"h\",\"I\",\"i\",\"J\",\"j\",\"K\",\"k\",\"L\",\"l\"\n",
    "    #                                              ,\"M\",\"m\",\"N\",\"n\",\"O\",\"o\",\"P\",\"p\",\"Q\",\"q\",\"R\",\"r\"\n",
    "    #                                              ,\"S\",\"s\",\"T\",\"t\",\"U\",\"u\",\"V\",\"v\",\"W\",\"w\",\"X\",\"x\"\n",
    "    #                                              ,\"Y\",\"y\",\"Z\",\"z\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"0\"\n",
    "    #                                              ,\"=\",\"_\",\"-\",\"$\",\"\\\"\",\"|\",\"¬£\",\"¬•\",\"¬Æ\",\"¬Ø\",\"‚ñΩ\",\"¬º\",\"¬Ω\",\"¬æ\"\n",
    "    #                                              ,\"√â\",\"√ó\",\"√°\",\"√§\",\"√©\",\"√≤\",\"√¥\",\"√ª√©\"))\n",
    "    final = \"\".join(u for u in text if u not in (\"?\", \".\", \";\", \":\", \"!\", '\"', \"‡πÜ\", \"‡∏Ø\",\"‚Ñ¢\",\"#\",\"/\"))\n",
    "    final = word_tokenize(final)\n",
    "    final = \" \".join(word for word in final)\n",
    "    final = \" \".join(word for word in final.split() \n",
    "                     if word.lower not in thai_stopwords)\n",
    "    return final\n",
    "df['text_tokens'] = df['texts'].apply(text_process)\n",
    "df.to_csv(\"text_tokent.csv\", index=False, encoding='utf-8-sig')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['text_tokens']]\n",
    "y = df['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡πÉ‡∏´‡πâ</td>\n",
       "      <td>13352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡∏ô‡∏±‡πà‡∏á</td>\n",
       "      <td>6322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡∏Ç‡πâ‡∏≤‡∏á</td>\n",
       "      <td>3648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡∏Å‡∏±‡∏ô</td>\n",
       "      <td>3058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤</td>\n",
       "      <td>11753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13798</th>\n",
       "      <td>VS</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13799</th>\n",
       "      <td>‡∏ã‡∏≤‡∏£‡∏™‡πå,</td>\n",
       "      <td>4873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13800</th>\n",
       "      <td>‡∏ï‡∏∑‡πà‡∏ô‡∏Å‡∏•‡∏±‡∏ß</td>\n",
       "      <td>5531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13801</th>\n",
       "      <td>1018521</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13802</th>\n",
       "      <td>rebound</td>\n",
       "      <td>2608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13803 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Index\n",
       "0           ‡πÉ‡∏´‡πâ  13352\n",
       "1          ‡∏ô‡∏±‡πà‡∏á   6322\n",
       "2          ‡∏Ç‡πâ‡∏≤‡∏á   3648\n",
       "3           ‡∏Å‡∏±‡∏ô   3058\n",
       "4      ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤  11753\n",
       "...         ...    ...\n",
       "13798        VS   1989\n",
       "13799    ‡∏ã‡∏≤‡∏£‡∏™‡πå,   4873\n",
       "13800  ‡∏ï‡∏∑‡πà‡∏ô‡∏Å‡∏•‡∏±‡∏ß   5531\n",
       "13801   1018521    226\n",
       "13802   rebound   2608\n",
       "\n",
       "[13803 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(analyzer=lambda x:x.split(' '))\n",
    "cvec.fit_transform(X_train['text_tokens'])\n",
    "cvec.vocabulary_\n",
    "# Get the vocabulary\n",
    "vocabulary = cvec.vocabulary_\n",
    "\n",
    "# Convert vocabulary to DataFrame\n",
    "df_vocabulary = pd.DataFrame(list(vocabulary.items()), columns=['Word', 'Index'])\n",
    "\n",
    "# Save the vocabulary to a CSV file\n",
    "# df_vocabulary.to_csv(\"vocabulary.csv\", index=False, encoding='utf-8-sig')\n",
    "df_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$</th>\n",
       "      <th>%</th>\n",
       "      <th>%(</th>\n",
       "      <th>%)</th>\n",
       "      <th>%**</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>'',</th>\n",
       "      <th>'‡∏Ñ‡∏ô‡∏ö‡∏π‡∏•</th>\n",
       "      <th>'‡∏á'</th>\n",
       "      <th>...</th>\n",
       "      <th>ü•πüíû</th>\n",
       "      <th>ü•∫</th>\n",
       "      <th>ü•∫üå∑üíñü§èüèª</th>\n",
       "      <th>ü•∫üò≠</th>\n",
       "      <th>ü•∫ü•∫</th>\n",
       "      <th>ü•∫ü•∫ü•∫ü•∫</th>\n",
       "      <th>üßë‚Äçüíªüë©‚Äçüíªüë®‚Äçüíª</th>\n",
       "      <th>üß°</th>\n",
       "      <th>üß°üëçüò¨</th>\n",
       "      <th>ü´†)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_tokens</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>‡πÉ‡∏´‡πâ ‡∏ô‡∏±‡πà‡∏á ‡∏Ç‡πâ‡∏≤‡∏á ‡∏Å‡∏±‡∏ô ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤ ‡∏≠ ‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠ ‡πÑ‡∏°‡πà ‡∏™‡∏ß‡∏¢ ‡πÄ‡∏•‡∏¢ ‡∏à‡∏∞ ‡πÉ‡∏´‡πâ ‡πÄ‡∏£‡∏≤ ‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ‡∏ô‡∏Ñ‡∏∏‡∏° ‡∏û‡∏≠ ‡∏ä‡πà‡∏ß‡∏á ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏ó‡∏µ‡πà ‡∏ï‡πâ‡∏≠‡∏á ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡πÄ‡∏£‡∏≤ ‡∏Å‡∏±‡∏ö ‡∏≠ ‡∏Å‡πá ‡∏¢‡∏±‡∏á ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô ‡∏≠‡∏¢‡∏π‡πà ‡∏ö‡πâ‡∏≤‡∏á ‡πÅ‡∏ï‡πà ‡∏´‡∏•‡∏±‡∏á ‡∏Å‡πá ‡πÑ‡∏°‡πà ‡πÑ‡∏î‡πâ ‡∏Ñ‡∏∏‡∏¢ ‡∏Å‡∏±‡∏ô ‡πÄ‡∏•‡∏¢ ‡∏Ñ‡πà‡∏∞ ‡∏°‡∏≤ ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô ‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ ‡∏Å‡πá ‡∏ï‡∏≠ ‡∏õ 6 ‡∏ô‡∏µ‡πà‡πÅ‡∏´‡∏•‡∏∞ ‡∏Ñ‡πà‡∏∞ ‡πÄ‡∏ß‡∏•‡∏≤ ‡πÄ‡∏à‡∏≠ ‡∏Å‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÇ‡∏£‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏Å‡πá ‡∏à‡∏∞ ‡πÄ‡∏•‡πà‡∏ô ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô ‡∏õ‡∏£‡∏Å‡∏ï‡∏¥ ‡πÅ‡∏ï‡πà ‡∏Å‡πá ‡πÅ‡∏≠‡∏ö ‡πÉ‡∏à‡πÄ‡∏ï‡πâ‡∏ô ‡∏≠‡∏¢‡∏π‡πà ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡πÄ‡∏ß‡∏•‡∏≤ ‡∏Ñ‡∏∏‡∏¢ ‡∏Å‡∏±‡∏ô ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ï‡∏±‡∏ß ‡πÉ‡∏Å‡∏•‡πâ ‡∏Å‡∏±‡∏ô ‡∏Å‡πá ‡πÄ‡∏•‡∏¢ ‡∏™‡∏á‡∏™‡∏±‡∏¢ ‡∏ô‡πà‡∏∞ ‡∏Ñ‡πà‡∏∞ ‡∏ß‡πà‡∏≤ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡∏ô‡∏µ‡πâ ‡πÉ‡∏ä‡πà ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏Å ‡∏£‡∏∂‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠ ‡πÄ‡∏õ‡πá‡∏ô ‡πÅ‡∏Ñ‡πà ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÉ‡∏ô ‡∏ß‡∏±‡∏¢ ‡∏ô‡∏µ‡πâ ‡∏Ñ‡∏∞</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‡πÄ‡∏û‡∏¥‡πà‡∏á ‡πÄ‡∏£‡∏¥‡πà‡∏° ‡∏á‡∏≤‡∏ô ‡∏¢‡∏±‡∏á ‡πÑ‡∏°‡πà ‡∏ñ‡∏∂‡∏á ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏ï‡πà ‡πÅ‡∏ü‡∏ô ‡∏ï‡∏¥‡∏î ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡πÄ‡∏£‡∏≤ ‡πÑ‡∏î‡πâ ‡∏Å‡∏±‡∏Å‡∏ï‡∏±‡∏ß 1 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå ‡∏Ñ‡∏£‡∏ö 1 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå ‡πÄ‡∏£‡∏≤ ‡∏ï‡∏£‡∏ß‡∏à ‡πÄ‡∏à‡∏≠ ‡∏ß‡πà‡∏≤ ‡∏ï‡∏¥‡∏î ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‡πÄ‡∏£‡∏≤ ‡πÑ‡∏°‡πà ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ ‡πÑ‡∏õ ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡πÑ‡∏î‡πâ ‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏à‡∏∞ ‡∏à‡πà‡∏≤‡∏¢ ‡πÄ‡∏á‡∏¥‡∏ô ‡∏ä‡πà‡∏ß‡∏á ‡∏ó‡∏µ‡πà ‡πÄ‡∏£‡∏≤ ‡∏´‡∏¢‡∏∏‡∏î ‡πÑ‡∏´‡∏° ‡∏Ñ‡∏∞</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‡πÄ‡∏Ñ‡∏•‡∏° ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏ö ‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡πÑ‡∏ó‡∏¢ ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏†‡∏±‡∏¢ ‡∏Å‡∏µ‡πà ‡∏ß‡∏±‡∏ô ‡∏ñ‡∏∂‡∏á ‡∏à‡∏∞ ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö ‡∏Ñ‡πà‡∏≤‡∏™‡∏¥‡∏ô‡πÑ‡∏´‡∏° ‡πÄ‡∏£‡∏≤ ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠ ‡∏Å‡∏±‡∏ö ‡∏ó‡∏≤‡∏á ‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡πÑ‡∏ó‡∏¢ ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏†‡∏±‡∏¢ ‡πÅ‡∏ó‡∏ö ‡∏ó‡∏∏‡∏Å ‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á ‡∏Å‡πá ‡πÑ‡∏°‡πà ‡πÑ‡∏î‡πâ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡∏≠‡∏∞‡πÑ‡∏£ ‡∏£‡∏ö‡∏Å‡∏ß‡∏ô ‡∏ú‡∏π‡πâ‡∏£‡∏π‡πâ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏õ‡∏• ‡πÄ‡∏£‡∏≤ ‡∏¢‡∏∑‡πà‡∏ô ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ 07022565 ‡∏ó‡∏µ‡πà ‡∏™‡∏ô ‡∏á ‡πÉ‡∏´‡∏ç‡πà</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‡∏Ñ‡∏∑‡∏≠ ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå ‡∏ô‡∏±‡πâ‡∏ô ‡∏°‡∏±‡∏ô ‡πÑ‡∏î‡πâ ‡πÄ‡∏Å‡∏¥‡∏î ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö ‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏≤ ‡∏â‡∏±‡∏ô ‡πÄ‡∏≠‡∏á ‡∏â‡∏±‡∏ô ‡∏¢‡∏±‡∏á ‡∏à‡∏≥‡πÑ‡∏î‡πâ ‡πÄ‡∏õ‡πá‡∏ô ‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô ‡∏à‡∏∂‡∏á ‡∏≠‡∏¢‡∏≤‡∏Å ‡πÅ‡∏ä‡∏£‡πå ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå ‡πÉ‡∏´‡πâ ‡∏ú‡∏π‡πâ ‡∏ó‡∏µ‡πà ‡πÑ‡∏î‡πâ ‡∏≠‡πà‡∏≤‡∏ô ‡∏£‡∏±‡∏ö‡∏£‡∏π‡πâ ‡πÉ‡∏ô ‡∏™‡∏¥‡πà‡∏á ‡∏ó‡∏µ‡πà ‡∏â‡∏±‡∏ô ‡πÑ‡∏î‡πâ ‡∏™‡∏±‡∏°‡∏ú‡∏±‡∏™ ‡πÅ‡∏•‡∏∞ ‡πÑ‡∏î‡πâ ‡πÄ‡∏´‡πá‡∏ô ‡πÉ‡∏ô ‡∏ß‡∏±‡∏ô‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô ‡∏ä‡πà‡∏ß‡∏á ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏ã‡∏∂‡πà‡∏á ‡∏â‡∏±‡∏ô ‡πÑ‡∏î‡πâ ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‡∏≠‡∏¢‡∏π‡πà ‡∏ó‡∏µ‡πà ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‡∏™‡∏∏‡πà‡∏° ‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á ‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡πá‡πÑ‡∏î‡πâ ‡∏Å‡∏•‡∏±‡∏ö‡∏ö‡πâ‡∏≤‡∏ô ‡πÉ‡∏ô ‡∏ä‡πà‡∏ß‡∏á ‡πÄ‡∏ó‡∏®‡∏Å‡∏≤‡∏•</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‡∏Ñ‡∏∑‡∏≠ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏û‡∏∂‡πà‡∏á ‡∏ï‡∏£‡∏ß‡∏Ñ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡πÅ‡∏•‡πâ‡∏ß ‡∏ú‡∏• ‡πÄ‡∏õ‡πá‡∏ô ‡∏ö‡∏ß‡∏Å ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ ‡∏Ñ‡∏∏‡∏¢ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏Å‡∏¥‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß ‡πÄ‡∏õ‡∏¥‡∏î ‡πÅ‡∏°‡∏™ ‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥ ‡∏ô‡∏µ‡πà ‡∏Ñ‡∏ß‡∏£ ‡∏ó‡∏≥ ‡πÑ‡∏á ‡∏î‡∏µ ‡∏Ñ‡∏∞ üò¢</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£ ‡∏ã‡∏µ ‡πÇ‡∏£‡πà ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏à‡∏µ‡∏ô ‡∏¢‡∏±‡∏á ‡∏´‡πâ‡∏≤‡∏° ‡∏≠‡∏≠‡∏Å ‡∏´‡πâ‡∏≤‡∏° ‡πÄ‡∏Ç‡πâ‡∏≤ ‡πÅ‡∏ï‡πà ‡∏™‡∏µ ‡∏à‡∏¥‡πâ‡∏ô ‡∏ú‡∏¥‡∏á ‡πÑ‡∏õ ‡∏´‡∏•‡∏≤‡∏¢ ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡πÅ‡∏°‡∏™ ‡∏Å‡πá ‡πÑ‡∏°‡πà ‡πÉ‡∏™‡πà</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‡πÄ‡∏õ‡πá‡∏ô ‡∏õ‡∏µ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡∏ö‡πà‡∏≠‡∏¢ ‡∏û‡∏≠ ‡∏ä‡πà‡∏ß‡∏á ‡πÄ‡∏ó‡∏≠‡∏° 2 ‡∏Å‡πá ‡∏°‡∏µ ‡∏à‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏Å‡∏±‡∏ô ‡∏Å‡πá ‡∏Ñ‡πà‡∏≠‡∏¢ ‡∏™‡∏ô‡∏¥‡∏ó ‡∏Å‡∏≥‡∏•‡∏±‡∏á ‡∏û‡∏≠‡∏î‡∏µ ‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏ï‡πà ‡∏à‡∏∞ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ‡πÄ‡∏£‡∏≤ ‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏ó‡∏µ‡πà ‡∏™‡∏ô‡∏¥‡∏ó ‡∏ï‡∏≤‡∏° ‡∏ó‡πâ‡∏≤‡∏¢ ‡πÄ‡∏™‡∏°‡∏≠ ‡∏Ñ‡∏á ‡πÄ‡∏õ‡πá‡∏ô ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ ‡πÄ‡∏£‡∏≤ ‡πÄ‡∏Ç‡πâ‡∏≤ ‡∏™‡∏±‡∏°‡∏Ñ‡∏° ‡πÑ‡∏°‡πà ‡πÄ‡∏Å‡πà‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πá ‡πÑ‡∏ß‡πâ‡πÉ‡∏à ‡πÅ‡∏Ñ‡πà ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô 1 ‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏≠‡πà‡∏∞ ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏õ‡πá‡∏ô ‡∏á‡∏µ‡πâ ‡πÄ‡∏£‡∏≤ ‡πÄ‡∏£‡∏¥‡πà‡∏° ‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å ‡∏Å‡πá ‡∏ä‡πà‡∏ß‡∏á ‡∏ô‡∏µ‡πâ‡πÅ‡∏´‡∏•‡∏∞ ‡∏Ñ‡πà‡∏∞ ‡∏Ñ‡∏∑‡∏≠ ‡∏Å‡∏•‡∏∏‡πà‡∏° ‡πÄ‡∏£‡∏≤ ‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï ‡∏û‡∏π‡∏î ‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏ß‡πà‡∏≤ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‡∏û‡∏∂‡πà‡∏á ‡∏°‡∏≤ ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏ß‡∏≠‡∏•‡πÄ‡∏•‡∏¢‡πå‡∏ö‡∏≠‡∏• ‡∏≠‡∏¢‡∏≤‡∏Å ‡∏ó‡∏£‡∏≤‡∏ö ‡∏ß‡πà‡∏≤ ‡πÉ‡∏ô ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ VNL 2022 ‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢ ‡∏°‡∏µ ‡∏ô‡∏±‡∏Å‡∏Å‡∏µ‡∏¨‡∏≤ ‡∏ó‡∏µ‡πà ‡∏Ñ‡∏∏‡πâ‡∏ô ‡∏ä‡∏∑‡πà‡∏≠ ‡∏Å‡∏±‡∏ö ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ä‡πà‡∏ô ‡∏ö‡∏≠‡∏™ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡πÄ‡∏•‡∏¢ ‡∏≠‡∏¢‡∏≤‡∏Å ‡∏ó‡∏£‡∏≤‡∏ö ‡∏ß‡πà‡∏≤ ‡∏ô‡πâ‡∏≠‡∏á ‡πÑ‡∏°‡πà ‡πÄ‡∏•‡πà‡∏ô ‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏£‡∏∑‡∏≠ ‡∏û‡∏±‡∏Å ‡∏Ñ‡∏∞ ‡πÑ‡∏°‡πà ‡πÄ‡∏´‡πá‡∏ô ‡πÉ‡∏ô ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á ‡πÄ‡∏≠‡∏î‡∏™‡πå VS ( ‡πÇ‡∏£‡∏Ñ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î , ‡πÇ‡∏£‡∏Ñ ‡∏ã‡∏≤‡∏£‡∏™‡πå, ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏Ç‡πâ‡∏´‡∏ß‡∏±‡∏î ‡∏ô‡∏Å ) ‡∏ú‡∏π‡πâ‡∏Ñ‡∏ô ‡∏´‡∏ß‡∏≤‡∏î‡∏Å‡∏•‡∏±‡∏ß ‡πÇ‡∏£‡∏Ñ ‡πÑ‡∏´‡∏ô ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡∏Å‡∏±‡∏ô ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏≠ ‡∏à‡∏±‡∏î ‡∏ó‡∏±‡πâ‡∏á 3 ‡πÇ‡∏£‡∏Ñ ‡∏≠‡∏¢‡∏π‡πà ‡πÉ‡∏ô ‡∏Å‡∏•‡∏∏‡πà‡∏° ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡∏ô‡∏∞ ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤ ‡πÄ‡∏Å‡∏¥‡∏î ‡πÉ‡∏ô ‡∏¢‡∏∏‡∏Ñ ‡∏´‡∏•‡∏±‡∏á ‡∏ó‡∏µ‡πà ‡∏ú‡∏π‡πâ‡∏Ñ‡∏ô ‡∏ï‡∏∑‡πà‡∏ô‡∏Å‡∏•‡∏±‡∏ß ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô ‡πÅ‡∏ï‡πà ‡πÑ‡∏°‡πà ‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡∏ß‡πà‡∏≤ ‡πÄ‡∏ó‡πà‡∏≤ ‡πÄ‡∏≠‡∏î‡∏™‡πå ‡πÉ‡∏ô ‡∏¢‡∏∏‡∏Ñ ‡∏ó‡∏µ‡πà ‡πÑ‡∏°‡πà ‡∏°‡∏µ ‡∏¢‡∏≤ ‡∏ï‡πâ‡∏≤‡∏ô ‡πÑ‡∏´‡∏°</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>httpswwwbangkokbiznewscomsocialpublic _ health 1018521 ‡∏™‡∏ò ‡∏¢‡∏Å ‚Äú Covid rebound ‚Äù ‡πÅ‡∏ô‡∏∞ ‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏¥‡∏ô ‡∏¢‡∏≤ ‡∏ï‡πâ‡∏≤‡∏ô ‡πÑ‡∏ß‡∏£‡∏±‡∏™ ‡∏ï‡∏≤‡∏° ‡∏´‡∏°‡∏≠ ‡∏™‡∏±‡πà‡∏á ‡∏™‡∏ò ‡∏¢‡∏Å ‡∏Å‡∏£‡∏ì‡∏µ ‡πÄ‡∏Å‡∏¥‡∏î ‚Äú Covid rebound ‚Äù ‡∏Ñ‡∏∑‡∏≠ ‡∏Å‡∏¥‡∏ô ‡∏¢‡∏≤ ‡∏ï‡πâ‡∏≤‡∏ô ‡πÑ‡∏ß‡∏£‡∏±‡∏™ ‡∏Ñ‡∏£‡∏ö ‡πÅ‡∏ï‡πà ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤ ‡∏ï‡∏¥‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠ ‡∏ã‡πâ‡∏≥ ‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô ‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡πÑ‡∏°‡πà ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á ‡∏Å‡∏¥‡∏ô ‡∏¢‡∏≤ ‡∏ï‡πâ‡∏≤‡∏ô ‡πÑ‡∏ß‡∏£‡∏±‡∏™ ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ ‡πÉ‡∏ä‡πâ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5742 rows √ó 13803 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    $  %  %(  %)  %**  &  '  \\\n",
       "text_tokens                                                                   \n",
       "‡πÉ‡∏´‡πâ ‡∏ô‡∏±‡πà‡∏á ‡∏Ç‡πâ‡∏≤‡∏á ‡∏Å‡∏±‡∏ô ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤ ‡∏≠ ‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠ ‡πÑ‡∏°‡πà ‡∏™‡∏ß‡∏¢ ‡πÄ‡∏•‡∏¢...  0  0   0   0    0  0  0   \n",
       "‡πÄ‡∏û‡∏¥‡πà‡∏á ‡πÄ‡∏£‡∏¥‡πà‡∏° ‡∏á‡∏≤‡∏ô ‡∏¢‡∏±‡∏á ‡πÑ‡∏°‡πà ‡∏ñ‡∏∂‡∏á ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏ï‡πà ‡πÅ‡∏ü‡∏ô ‡∏ï...  0  0   0   0    0  0  0   \n",
       "‡πÄ‡∏Ñ‡∏•‡∏° ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏ö ‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡πÑ‡∏ó‡∏¢ ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏†‡∏±‡∏¢ ‡∏Å‡∏µ‡πà ‡∏ß...  0  0   0   0    0  0  0   \n",
       "‡∏Ñ‡∏∑‡∏≠ ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå ‡∏ô‡∏±‡πâ‡∏ô ‡∏°‡∏±‡∏ô ‡πÑ‡∏î‡πâ ‡πÄ‡∏Å‡∏¥‡∏î ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö ‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏≤ ...  0  0   0   0    0  0  0   \n",
       "‡∏Ñ‡∏∑‡∏≠ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏û‡∏∂‡πà‡∏á ‡∏ï‡∏£‡∏ß‡∏Ñ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡πÅ‡∏•‡πâ‡∏ß ‡∏ú‡∏• ‡πÄ‡∏õ‡πá‡∏ô ‡∏ö‡∏ß‡∏Å ‡πÅ‡∏•‡πâ...  0  0   0   0    0  0  0   \n",
       "...                                                .. ..  ..  ..  ... .. ..   \n",
       "‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£ ‡∏ã‡∏µ ‡πÇ‡∏£‡πà ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏à‡∏µ‡∏ô ‡∏¢‡∏±‡∏á ‡∏´‡πâ‡∏≤‡∏° ‡∏≠‡∏≠‡∏Å ‡∏´‡πâ‡∏≤‡∏° ‡πÄ‡∏Ç‡πâ‡∏≤...  0  0   0   0    0  0  0   \n",
       "‡πÄ‡∏õ‡πá‡∏ô ‡∏õ‡∏µ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡∏ö‡πà‡∏≠‡∏¢ ‡∏û‡∏≠ ‡∏ä‡πà‡∏ß‡∏á ‡πÄ‡∏ó‡∏≠‡∏° 2 ‡∏Å‡πá ‡∏°‡∏µ...  0  0   0   0    0  0  0   \n",
       "‡∏û‡∏∂‡πà‡∏á ‡∏°‡∏≤ ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏ß‡∏≠‡∏•‡πÄ‡∏•‡∏¢‡πå‡∏ö‡∏≠‡∏• ‡∏≠‡∏¢‡∏≤‡∏Å ‡∏ó‡∏£‡∏≤‡∏ö ‡∏ß‡πà‡∏≤ ‡πÉ‡∏ô ‡∏£‡∏≤‡∏¢‡∏Å...  0  0   0   0    0  0  0   \n",
       "‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á ‡πÄ‡∏≠‡∏î‡∏™‡πå VS ( ‡πÇ‡∏£‡∏Ñ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î , ‡πÇ‡∏£‡∏Ñ ‡∏ã‡∏≤‡∏£‡∏™‡πå, ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏Ç...  0  0   0   0    0  0  0   \n",
       "httpswwwbangkokbiznewscomsocialpublic _ health ...  0  0   0   0    0  0  0   \n",
       "\n",
       "                                                    '',  '‡∏Ñ‡∏ô‡∏ö‡∏π‡∏•  '‡∏á'  ...  ü•πüíû  \\\n",
       "text_tokens                                                           ...       \n",
       "‡πÉ‡∏´‡πâ ‡∏ô‡∏±‡πà‡∏á ‡∏Ç‡πâ‡∏≤‡∏á ‡∏Å‡∏±‡∏ô ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤ ‡∏≠ ‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠ ‡πÑ‡∏°‡πà ‡∏™‡∏ß‡∏¢ ‡πÄ‡∏•‡∏¢...    0       0    0  ...   0   \n",
       "‡πÄ‡∏û‡∏¥‡πà‡∏á ‡πÄ‡∏£‡∏¥‡πà‡∏° ‡∏á‡∏≤‡∏ô ‡∏¢‡∏±‡∏á ‡πÑ‡∏°‡πà ‡∏ñ‡∏∂‡∏á ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏ï‡πà ‡πÅ‡∏ü‡∏ô ‡∏ï...    0       0    0  ...   0   \n",
       "‡πÄ‡∏Ñ‡∏•‡∏° ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏ö ‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡πÑ‡∏ó‡∏¢ ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏†‡∏±‡∏¢ ‡∏Å‡∏µ‡πà ‡∏ß...    0       0    0  ...   0   \n",
       "‡∏Ñ‡∏∑‡∏≠ ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå ‡∏ô‡∏±‡πâ‡∏ô ‡∏°‡∏±‡∏ô ‡πÑ‡∏î‡πâ ‡πÄ‡∏Å‡∏¥‡∏î ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö ‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏≤ ...    0       0    0  ...   0   \n",
       "‡∏Ñ‡∏∑‡∏≠ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏û‡∏∂‡πà‡∏á ‡∏ï‡∏£‡∏ß‡∏Ñ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡πÅ‡∏•‡πâ‡∏ß ‡∏ú‡∏• ‡πÄ‡∏õ‡πá‡∏ô ‡∏ö‡∏ß‡∏Å ‡πÅ‡∏•‡πâ...    0       0    0  ...   0   \n",
       "...                                                 ...     ...  ...  ...  ..   \n",
       "‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£ ‡∏ã‡∏µ ‡πÇ‡∏£‡πà ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏à‡∏µ‡∏ô ‡∏¢‡∏±‡∏á ‡∏´‡πâ‡∏≤‡∏° ‡∏≠‡∏≠‡∏Å ‡∏´‡πâ‡∏≤‡∏° ‡πÄ‡∏Ç‡πâ‡∏≤...    0       0    0  ...   0   \n",
       "‡πÄ‡∏õ‡πá‡∏ô ‡∏õ‡∏µ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡∏ö‡πà‡∏≠‡∏¢ ‡∏û‡∏≠ ‡∏ä‡πà‡∏ß‡∏á ‡πÄ‡∏ó‡∏≠‡∏° 2 ‡∏Å‡πá ‡∏°‡∏µ...    0       0    0  ...   0   \n",
       "‡∏û‡∏∂‡πà‡∏á ‡∏°‡∏≤ ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏ß‡∏≠‡∏•‡πÄ‡∏•‡∏¢‡πå‡∏ö‡∏≠‡∏• ‡∏≠‡∏¢‡∏≤‡∏Å ‡∏ó‡∏£‡∏≤‡∏ö ‡∏ß‡πà‡∏≤ ‡πÉ‡∏ô ‡∏£‡∏≤‡∏¢‡∏Å...    0       0    0  ...   0   \n",
       "‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á ‡πÄ‡∏≠‡∏î‡∏™‡πå VS ( ‡πÇ‡∏£‡∏Ñ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î , ‡πÇ‡∏£‡∏Ñ ‡∏ã‡∏≤‡∏£‡∏™‡πå, ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏Ç...    0       0    0  ...   0   \n",
       "httpswwwbangkokbiznewscomsocialpublic _ health ...    0       0    0  ...   0   \n",
       "\n",
       "                                                    ü•∫  ü•∫üå∑üíñü§èüèª  ü•∫üò≠  ü•∫ü•∫  ü•∫ü•∫ü•∫ü•∫  \\\n",
       "text_tokens                                                                  \n",
       "‡πÉ‡∏´‡πâ ‡∏ô‡∏±‡πà‡∏á ‡∏Ç‡πâ‡∏≤‡∏á ‡∏Å‡∏±‡∏ô ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤ ‡∏≠ ‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠ ‡πÑ‡∏°‡πà ‡∏™‡∏ß‡∏¢ ‡πÄ‡∏•‡∏¢...  0      0   0   0     0   \n",
       "‡πÄ‡∏û‡∏¥‡πà‡∏á ‡πÄ‡∏£‡∏¥‡πà‡∏° ‡∏á‡∏≤‡∏ô ‡∏¢‡∏±‡∏á ‡πÑ‡∏°‡πà ‡∏ñ‡∏∂‡∏á ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏ï‡πà ‡πÅ‡∏ü‡∏ô ‡∏ï...  0      0   0   0     0   \n",
       "‡πÄ‡∏Ñ‡∏•‡∏° ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏ö ‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡πÑ‡∏ó‡∏¢ ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏†‡∏±‡∏¢ ‡∏Å‡∏µ‡πà ‡∏ß...  0      0   0   0     0   \n",
       "‡∏Ñ‡∏∑‡∏≠ ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå ‡∏ô‡∏±‡πâ‡∏ô ‡∏°‡∏±‡∏ô ‡πÑ‡∏î‡πâ ‡πÄ‡∏Å‡∏¥‡∏î ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö ‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏≤ ...  0      0   0   0     0   \n",
       "‡∏Ñ‡∏∑‡∏≠ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏û‡∏∂‡πà‡∏á ‡∏ï‡∏£‡∏ß‡∏Ñ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡πÅ‡∏•‡πâ‡∏ß ‡∏ú‡∏• ‡πÄ‡∏õ‡πá‡∏ô ‡∏ö‡∏ß‡∏Å ‡πÅ‡∏•‡πâ...  0      0   0   0     0   \n",
       "...                                                ..    ...  ..  ..   ...   \n",
       "‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£ ‡∏ã‡∏µ ‡πÇ‡∏£‡πà ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏à‡∏µ‡∏ô ‡∏¢‡∏±‡∏á ‡∏´‡πâ‡∏≤‡∏° ‡∏≠‡∏≠‡∏Å ‡∏´‡πâ‡∏≤‡∏° ‡πÄ‡∏Ç‡πâ‡∏≤...  0      0   0   0     0   \n",
       "‡πÄ‡∏õ‡πá‡∏ô ‡∏õ‡∏µ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡∏ö‡πà‡∏≠‡∏¢ ‡∏û‡∏≠ ‡∏ä‡πà‡∏ß‡∏á ‡πÄ‡∏ó‡∏≠‡∏° 2 ‡∏Å‡πá ‡∏°‡∏µ...  0      0   0   0     0   \n",
       "‡∏û‡∏∂‡πà‡∏á ‡∏°‡∏≤ ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏ß‡∏≠‡∏•‡πÄ‡∏•‡∏¢‡πå‡∏ö‡∏≠‡∏• ‡∏≠‡∏¢‡∏≤‡∏Å ‡∏ó‡∏£‡∏≤‡∏ö ‡∏ß‡πà‡∏≤ ‡πÉ‡∏ô ‡∏£‡∏≤‡∏¢‡∏Å...  0      0   0   0     0   \n",
       "‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á ‡πÄ‡∏≠‡∏î‡∏™‡πå VS ( ‡πÇ‡∏£‡∏Ñ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î , ‡πÇ‡∏£‡∏Ñ ‡∏ã‡∏≤‡∏£‡∏™‡πå, ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏Ç...  0      0   0   0     0   \n",
       "httpswwwbangkokbiznewscomsocialpublic _ health ...  0      0   0   0     0   \n",
       "\n",
       "                                                    üßë‚Äçüíªüë©‚Äçüíªüë®‚Äçüíª  üß°  üß°üëçüò¨  ü´†)  \n",
       "text_tokens                                                                \n",
       "‡πÉ‡∏´‡πâ ‡∏ô‡∏±‡πà‡∏á ‡∏Ç‡πâ‡∏≤‡∏á ‡∏Å‡∏±‡∏ô ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤ ‡∏≠ ‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠ ‡πÑ‡∏°‡πà ‡∏™‡∏ß‡∏¢ ‡πÄ‡∏•‡∏¢...          0  0    0   0  \n",
       "‡πÄ‡∏û‡∏¥‡πà‡∏á ‡πÄ‡∏£‡∏¥‡πà‡∏° ‡∏á‡∏≤‡∏ô ‡∏¢‡∏±‡∏á ‡πÑ‡∏°‡πà ‡∏ñ‡∏∂‡∏á ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏ï‡πà ‡πÅ‡∏ü‡∏ô ‡∏ï...          0  0    0   0  \n",
       "‡πÄ‡∏Ñ‡∏•‡∏° ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏Å‡∏±‡∏ö ‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡πÑ‡∏ó‡∏¢ ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏†‡∏±‡∏¢ ‡∏Å‡∏µ‡πà ‡∏ß...          0  0    0   0  \n",
       "‡∏Ñ‡∏∑‡∏≠ ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå ‡∏ô‡∏±‡πâ‡∏ô ‡∏°‡∏±‡∏ô ‡πÑ‡∏î‡πâ ‡πÄ‡∏Å‡∏¥‡∏î ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö ‡∏ï‡∏±‡∏ß‡πÄ‡∏£‡∏≤ ...          0  0    0   0  \n",
       "‡∏Ñ‡∏∑‡∏≠ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏û‡∏∂‡πà‡∏á ‡∏ï‡∏£‡∏ß‡∏Ñ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡πÅ‡∏•‡πâ‡∏ß ‡∏ú‡∏• ‡πÄ‡∏õ‡πá‡∏ô ‡∏ö‡∏ß‡∏Å ‡πÅ‡∏•‡πâ...          0  0    0   0  \n",
       "...                                                       ... ..  ...  ..  \n",
       "‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£ ‡∏ã‡∏µ ‡πÇ‡∏£‡πà ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏à‡∏µ‡∏ô ‡∏¢‡∏±‡∏á ‡∏´‡πâ‡∏≤‡∏° ‡∏≠‡∏≠‡∏Å ‡∏´‡πâ‡∏≤‡∏° ‡πÄ‡∏Ç‡πâ‡∏≤...          0  0    0   0  \n",
       "‡πÄ‡∏õ‡πá‡∏ô ‡∏õ‡∏µ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î ‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå ‡∏ö‡πà‡∏≠‡∏¢ ‡∏û‡∏≠ ‡∏ä‡πà‡∏ß‡∏á ‡πÄ‡∏ó‡∏≠‡∏° 2 ‡∏Å‡πá ‡∏°‡∏µ...          0  0    0   0  \n",
       "‡∏û‡∏∂‡πà‡∏á ‡∏°‡∏≤ ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏ß‡∏≠‡∏•‡πÄ‡∏•‡∏¢‡πå‡∏ö‡∏≠‡∏• ‡∏≠‡∏¢‡∏≤‡∏Å ‡∏ó‡∏£‡∏≤‡∏ö ‡∏ß‡πà‡∏≤ ‡πÉ‡∏ô ‡∏£‡∏≤‡∏¢‡∏Å...          0  0    0   0  \n",
       "‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á ‡πÄ‡∏≠‡∏î‡∏™‡πå VS ( ‡πÇ‡∏£‡∏Ñ ‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î , ‡πÇ‡∏£‡∏Ñ ‡∏ã‡∏≤‡∏£‡∏™‡πå, ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏Ç...          0  0    0   0  \n",
       "httpswwwbangkokbiznewscomsocialpublic _ health ...          0  0    0   0  \n",
       "\n",
       "[5742 rows x 13803 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow = cvec.transform(X_train['text_tokens'])\n",
    "pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train['text_tokens'])\n",
    "dt = pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train['text_tokens'])\n",
    "dt\n",
    "# dt.to_csv(\"feature.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 7 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.75      0.86      0.80       591\n",
      "         neu       0.93      0.78      0.85      1741\n",
      "         pos       0.48      0.82      0.61       285\n",
      "\n",
      "    accuracy                           0.80      2617\n",
      "   macro avg       0.72      0.82      0.75      2617\n",
      "weighted avg       0.84      0.80      0.81      2617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rosary\\Desktop\\nlp\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a pipeline with TF-IDF, Logistic Regression, and hyperparameter tuning\n",
    "model = make_pipeline(TfidfVectorizer(analyzer=lambda x: x.split(' ')), LogisticRegression())\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(model, param_grid, cv=20, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(df['text_tokens'], df['category'])\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions on the test set\n",
    "test_predictions = best_model.predict(X_test['text_tokens'])\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(test_predictions, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 7 candidates, totalling 140 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.67      0.78      0.72       572\n",
      "         neu       0.89      0.72      0.80      1796\n",
      "         pos       0.33      0.65      0.44       249\n",
      "\n",
      "    accuracy                           0.73      2617\n",
      "   macro avg       0.63      0.72      0.65      2617\n",
      "weighted avg       0.79      0.73      0.75      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a pipeline with TF-IDF, Logistic Regression, and hyperparameter tuning\n",
    "model = make_pipeline(TfidfVectorizer(analyzer=lambda x: x.split(' ')), LogisticRegression(max_iter=1000000))\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(model, param_grid, cv=20, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train['text_tokens'], y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions on the test set\n",
    "test_predictions = best_model.predict(X_test['text_tokens'])\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(test_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 7 candidates, totalling 140 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.66      0.67      0.67       657\n",
      "         neu       0.70      0.74      0.72      1367\n",
      "         pos       0.52      0.43      0.47       593\n",
      "\n",
      "    accuracy                           0.65      2617\n",
      "   macro avg       0.63      0.62      0.62      2617\n",
      "weighted avg       0.65      0.65      0.65      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Apply Random Over-sampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train['text_tokens'].values.reshape(-1, 1), y_train)\n",
    "\n",
    "# Create a pipeline with TF-IDF, Logistic Regression, and hyperparameter tuning\n",
    "model = make_pipeline(TfidfVectorizer(analyzer=lambda x: x.split(' ')), LogisticRegression(max_iter=1000000))\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(model, param_grid, cv=20, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_resampled.flatten(), y_resampled)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions on the test set\n",
    "test_predictions = best_model.predict(X_test['text_tokens'])\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(test_predictions, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 7 candidates, totalling 140 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.76      0.67      0.71       766\n",
      "         neu       0.63      0.82      0.71      1122\n",
      "         pos       0.67      0.45      0.54       729\n",
      "\n",
      "    accuracy                           0.67      2617\n",
      "   macro avg       0.69      0.64      0.65      2617\n",
      "weighted avg       0.68      0.67      0.66      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Apply Random Under-sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train['text_tokens'].values.reshape(-1, 1), y_train)\n",
    "\n",
    "# Create a pipeline with TF-IDF, Logistic Regression, and hyperparameter tuning\n",
    "model = make_pipeline(TfidfVectorizer(analyzer=lambda x: x.split(' ')), LogisticRegression(max_iter=1000000))\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(model, param_grid, cv=20, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_resampled.flatten(), y_resampled)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions on the test set\n",
    "test_predictions = best_model.predict(X_test['text_tokens'])\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(test_predictions, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=1000000, solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=1000000, solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('logisticregression',\n",
       "                 LogisticRegression(max_iter=1000000, solver='liblinear'))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# dv = DictVectorizer(sparse=True)\n",
    "# lr = LogisticRegression(solver='liblinear', max_iter=1000000)\n",
    "# tran_sparse = dv.fit_transform(train_bow)\n",
    "# # lr = make_pipeline(StandardScaler(with_mean=False), LogisticRegression(solver='liblinear', max_iter=1000000))\n",
    "# lr.fit(tran_sparse, y_train)\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Assuming train_bow is a sparse matrix (e.g., a scipy.sparse.csr_matrix)\n",
    "train_bow_sparse = csr_matrix(train_bow)\n",
    "\n",
    "lr = make_pipeline(LogisticRegression(solver='liblinear', max_iter=1000000))\n",
    "lr.fit(train_bow_sparse, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.65      0.78      0.71       565\n",
      "         neu       0.88      0.72      0.79      1772\n",
      "         pos       0.34      0.59      0.43       280\n",
      "\n",
      "    accuracy                           0.72      2617\n",
      "   macro avg       0.62      0.70      0.64      2617\n",
      "weighted avg       0.77      0.72      0.73      2617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "test_bow = cvec.transform(X_test['text_tokens'])\n",
    "test_predictions = lr.predict(test_bow)\n",
    "test_bow = cvec.transform(X_test['text_tokens'])\n",
    "test_predictions = lr.predict(test_bow)\n",
    "print(classification_report(test_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text = '‡∏ú‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß'\n",
    "my_tokens = text_process(my_text)\n",
    "my_bow = cvec.transform(pd.Series([my_tokens]))\n",
    "my_predictions = lr.predict(my_bow)\n",
    "my_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.59      0.60      0.60       661\n",
      "         neu       0.71      0.70      0.71      1476\n",
      "         pos       0.41      0.42      0.42       480\n",
      "\n",
      "    accuracy                           0.63      2617\n",
      "   macro avg       0.57      0.57      0.57      2617\n",
      "weighted avg       0.63      0.63      0.63      2617\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.sparse import csr_matrix\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_bow_vectorized = csr_matrix(train_bow)\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "pipeline = make_pipeline(dt)\n",
    "pipeline.fit(train_bow_vectorized, y_train)\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "test_bow = cvec.transform(X_test['text_tokens'])\n",
    "test_predictions = pipeline.predict(test_bow)\n",
    "test_bow = cvec.transform(X_test['text_tokens'])\n",
    "test_predictions = pipeline.predict(test_bow)\n",
    "print(classification_report(test_predictions, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
